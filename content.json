{"pages":[],"posts":[{"title":"ControllerAdvice失效","text":"jar包和本地冲突,不想使用jar包的解决方案 接手了一个项目, 整个项目没有使用过自定义异常, 自己加入了全局异常无效 自己加入的全局异常如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.freemud.delivery.aop;import com.freemud.delivery.entity.enums.ResultCodeEnum;import com.freemud.delivery.entity.exception.DeliveryException;import com.freemud.delivery.entity.util.ExceptionUtils;import com.freemud.delivery.entity.vo.ApiResult;import lombok.extern.slf4j.Slf4j;import org.springframework.validation.ObjectError;import org.springframework.web.bind.MethodArgumentNotValidException;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.RestControllerAdvice;import java.util.List;import java.util.stream.Collectors;@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler { @ExceptionHandler({MethodArgumentNotValidException.class}) public ApiResult handler(MethodArgumentNotValidException e) { List&lt;String&gt; errorList = e.getBindingResult().getAllErrors() .stream() .map(ObjectError::getDefaultMessage) .map(String::valueOf) .collect(Collectors.toList()); return new ApiResult(ResultCodeEnum.PARAM_ERROR, errorList); } @ExceptionHandler({DeliveryException.class}) public ApiResult handler(DeliveryException e) { return new ApiResult(e.getCode(), e.getMessage(), null); } @ExceptionHandler({Exception.class}) public ApiResult handler(Exception e) { log.error(ExceptionUtils.getFullStackTrace(e)); return new ApiResult(ResultCodeEnum.SYSTEM_ERROR); }} 使用时发现并没有生效,当我故意入参错误时,报错如下: 122020-11-06 17:51:51,113 WARN deliverycenter (AbstractHandlerExceptionResolver.java:140) Resolved [org.springframework.web.bind.MethodArgumentNotValidException: Validation failed for argument at index 0 in method: public com.freemud.delivery.entity.vo.ApiResult&lt;com.freemud.delivery.entity.vo.PageResult&lt;com.freemud.delivery.entity.vo.service.delivery.DeliveryVO&gt;&gt; com.freemud.delivery.service.controller.QueryDeliveryController.queryListByDeliveryStatus(com.freemud.delivery.entity.vo.service.delivery.QueryDeliveryListReqVO), with 1 error(s): [Field error in object 'queryDeliveryListReqVO' on field 'partnerId': rejected value []; codes [NotBlank.queryDeliveryListReqVO.partnerId,NotBlank.partnerId,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [queryDeliveryListReqVO.partnerId,partnerId]; arguments []; default message [partnerId]]; default message [partnerId不能为空]] ] 我在console中搜索我的这个bean时发现这个提示: 122020-11-06 17:55:52,459 INFO deliverycenter (ExceptionHandlerExceptionResolver.java:288) Detected @ExceptionHandler methods in platformExceptionHandler2020-11-06 17:55:52,459 INFO deliverycenter (ExceptionHandlerExceptionResolver.java:288) Detected @ExceptionHandler methods in globalExceptionHandler 原来这个服务引入了公司的一个基础包; 这个包里已经有了全局异常; 这个类如下: 123456789101112131415161718192021222324252627282930//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package com.freemud.framework.exception;import com.freemud.framework.constants.SysStatusCode;import com.freemud.framework.result.ApiResult;import com.freemud.framework.util.Utils;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;@ControllerAdvice@ResponseBodypublic class PlatformExceptionHandler { public PlatformExceptionHandler() { } @ExceptionHandler({Exception.class}) public ApiResult handleException() { return new ApiResult(SysStatusCode.SYSTEM_ERROR); } @ExceptionHandler({PlatformException.class}) public ApiResult handlePlatformException(PlatformException platformException) { return Utils.notNull(platformException.getCode()) ? new ApiResult(platformException.getCode(), platformException.getMsg()) : new ApiResult(SysStatusCode.SYSTEM_ERROR); }} 我认为这个全局异常处理太差劲了; 完全没办法满足我( 同时我有点不理解了,原来是有自定义异常类的; 但是整个项目从来没有见到过一个使用的地方) 所以我现在需要做的事情就是让基础jar包的失效,使用我自己的全局异常处理 这时候在SpringBoot启动类中的排除这一个bean的注入,代码如下: 12345@ComponentScan(value = &quot;com.free.*&quot;, excludeFilters = @ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, classes = {PlatformExceptionHandler.class} )) 重启服务,调试成功","link":"/2020/11/06/ControllerAdvice%E5%A4%B1%E6%95%88/"},{"title":"git网站","text":"如果想使用好git;那么git的命令一定是要使用的; 一直使用idea自带的并不能让自己完全熟悉git 整理下git的学习网站 网址 网站描述 https://git-scm.com/book/zh/v2 git 官网教程 https://www.zhihu.com/question/29929269 知乎的一篇推荐 https://learngitbranching.js.org git learning 图文教程 https://github.com/k88hudson/git-flight-rules/blob/master/README_zh-CN.md git flight rules https://www.jianshu.com/p/964de879904a commit 合并 https://segmentfault.com/a/1190000009048911 git commit 提交规范","link":"/2020/10/15/git/"},{"title":"log打印时增加链路id","text":"为mq服务生成一个trackingNo 前提 在使用分布式项目中,一个用户的一次请求应该是一条链路,当需要查找日志时, 可以根据一个id来将用户在所有子模块中的流程都获取到, 这时候在两个服务之间需要传递这个id(后面称它为tid). 然后在日志打印中将tid输出,elk搜集到后,通过tid就可以查到所有日志; 现在在查看问题的时候发现mq是没有这个tid的,因此自己加入到项目中,便于之后日志查询 ---- 实际中如果发送mq的地方有tid可以加入到mq的header中;在aop中获取该tid 熟悉下aopspringboot的版本12345-- springboot的版本为id 'org.springframework.boot' version '2.3.2.RELEASE'-- aop需要引入implementation 'org.springframework.boot:spring-boot-starter-aop' 开始测试aop各个注解对应的执行顺序 验证的注解: @Before @After @Around @AfterThrowing @AfterReturning 测试代码切面1234567891011121314151617181920212223242526272829303132333435363738@Aspect@Componentpublic class TrackingNoAop {// 在项目中实际使用注解时启动报错,发现需要使用全路径,可能是公司项目包版本低的原因,不多深究// @Pointcut(&quot;@annotation(TIDLog)&quot;) @Pointcut(&quot;execution(* com.wyj.daily.test_project.controller..*.*(..))&quot;) public void aspTrackingNo(){ } //2 @Before(&quot;aspTrackingNo()&quot;) public void before(JoinPoint joinPoint) { System.out.println(&quot;before&quot;); } //4 @After(&quot;aspTrackingNo()&quot;) public void after() { System.out.println(&quot;after&quot;); } //1 @Around(&quot;aspTrackingNo()&quot;) public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(&quot;around&quot;); Object proceed = proceedingJoinPoint.proceed(proceedingJoinPoint.getArgs()); System.out.println(&quot;proceed = &quot; + proceed); } //3 @AfterThrowing(pointcut = &quot;aspTrackingNo()&quot;, throwing = &quot;e&quot;) public void afterThrowing(JoinPoint joinPoint, Exception e) { System.out.println(&quot;afterThrowing&quot;); } //3 @AfterReturning(pointcut = &quot;aspTrackingNo()&quot;) public void afterReturning() { System.out.println(&quot;afterReturning &quot;); }} 被切的类1234567@GetMapping(&quot;/testAop/{type}&quot;)public ResponseEntity&lt;String&gt; testAop(@PathVariable Integer type) { if (type == 1) { throw new RuntimeException(); } return ResponseEntity.ok(&quot;哈哈&quot;);} 正常时打印12345aroundbeforeafterReturning afterproceed = &lt;200 OK OK,哈哈,[]&gt; 抛异常时打印1234aroundbeforeafterThrowingafter 结论:请求-&gt; around开始 -&gt; before -&gt; 执行方法(proceed)-&gt; afterThrowing/afterReturning -&gt;after -&gt; around 结束 代码非mq的时候(公司之前封装的)tid的本地线程变量:1234567891011121314151617181920public class LogTreadLocal { private static final ThreadLocal&lt;String&gt; trackingNoThreadLocal = new ThreadLocal(); public LogTreadLocal() { } public static void setTrackingNo(String trackingNo) { trackingNoThreadLocal.set(trackingNo); } public static String getTrackingNo() { String trackNo = (String)trackingNoThreadLocal.get(); return trackNo; } public static void removeTrackingNo() { trackingNoThreadLocal.remove(); }} 拦截器12345678910111213141516171819public class LogTrackNoInterceptor implements HandlerInterceptor { public LogTrackNoInterceptor() { } //假设两个服务之前会传递的这个值放在header中,name为:x-transaction-id public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) { LogTreadLocal.setTrackingNo(StringUtils.isEmpty(httpServletRequest.getHeader(&quot;x-transaction-id&quot;)) ? UUID.randomUUID().toString().replaceAll(&quot;-&quot;, &quot;&quot;) : httpServletRequest.getHeader(&quot;x-transaction-id&quot;)); return true; } public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) { } public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) { LogTreadLocal.removeTrackingNo(); }} 日志打印时输入tid即可本次调整关于mq消费者的日志打印原本熟悉切面后,也准备放入本地线程变量中,但是公司使用logback进行日志打印, logback中有一个MDC功能,本质上也是本地线程变量,因此准备直接使用logback的MDC, 两者也不存在冲突 注解1234@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface TIDLog {} 切面12345678910111213141516171819202122232425262728@Aspect@Component@Slf4jpublic class TrackingNoAop { @Pointcut(&quot;@annotation(com.freemud.delivery.annotation.TIDLog)&quot;) public void trackingNo() { } //2 @Before(&quot;trackingNo()&quot;) public void before(JoinPoint joinPoint) { MDC.put(&quot;tid&quot;, UUIDUtils.getUUID()); } @After(&quot;trackingNo()&quot;) public void after() { MDC.remove(&quot;tid&quot;); } @AfterThrowing(pointcut = &quot;trackingNo()&quot;, throwing = &quot;e&quot;) public void afterThrowing(Exception e) { log.error(ExceptionUtils.getFullStackOnLine(e)); }} logback调整appender-&gt;encoder-&gt;pattern下增加该tid打印,比如: &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%X{tid}] %-5level %logger{36} - %msg%n&lt;/pattern&gt; ​ 新增日志打印工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Slf4jpublic class LogUtils { public static BiFunction&lt;Long, Long, Long&gt; takeUpTime = (startTime, endTime) -&gt; { if (startTime != null &amp;&amp; endTime != null) { return endTime - startTime; } return null; }; public static void info(String message, Object requestData, Object responseData) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.info(&quot;ClassName: {} ,MethodName: {} , MethodLine: {}, Message: {} , RequestData: {} ,ResponseData: {}&quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), message, JSONObject.toJSONString(requestData), JSONObject.toJSONString(responseData) ); } public static void info(String message, Object requestData, Object responseData, Long startTime, Long endTime) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.info(&quot;ClassName: {} ,MethodName: {} , MethodLine: {} , startTime: {} , takeUpTime: {}&quot; + &quot;, Message: {} , RequestData: {} ,ResponseData: {} &quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), startTime, takeUpTime.apply(startTime, endTime), message, JSONObject.toJSONString(requestData), JSONObject.toJSONString(responseData) ); } public static void error(String message, Object requestData, Exception e) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.error(&quot;ClassName: {} ,MethodName: {} , MethodLine: {}, Message: {} , RequestData: {} ,ExceptionInfo: {}&quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), message, JSONObject.toJSONString(requestData), ExceptionUtils.getFullStackTrace(e) ); } public static void error(String message, Object requestData, Long startTime, Long endTime, Exception e) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.error(&quot;ClassName: {} ,MethodName: {} , MethodLine: {}, startTime: {} , takeUpTime: {} ,&quot; + &quot; Message: {} , RequestData: {} , ExceptionInfo: {} , &quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), message, JSONObject.toJSONString(requestData), startTime, takeUpTime.apply(startTime, endTime), ExceptionUtils.getFullStackTrace(e) ); }}","link":"/2020/10/21/log%E6%89%93%E5%8D%B0%E6%97%B6%E5%A2%9E%E5%8A%A0%E9%93%BE%E8%B7%AFid/"},{"title":"quartz使用","text":"优先使用xxljob;条件不允许再考虑quartz 背景​ 有一个ka项目的定时任务服务是单节点,而这个明显是不合理的,准备搞成支持分布式的定时任务,第一个想到的xxljob;但是由于项目是运行在别人公司的服务器上,身不由己,最终选择使用quartz来进行定时任务的管理 效果​ 因为quartz是没有界面的; 之前的公司甚至见过通过查库来增加定时任务,因此希望实现的效果就是能够通过接口来对定时任务进行增删改查(界面是不可能的,只能接口了),功能如下: 新增定时任务 修改定时任务的corn表达式 暂停一个定时任务 删除一个定时任务 查询所有定时任务的列表 除此之外,我并不想太多的动之前的代码,因此尽量调整量小一些 流程 1.引包 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt; &lt;/dependency&gt; 2.建表语句: 不要百度,因为quartz1.0和2.0建表不一样; 不同数据库也可能有一些差别, 建表语句在github上quartz.core包的resource下,可以先看下项目引用的版本再到github上切换对应的版本上找自己使用的数据库初始化语句,最新master分支建表的位置 3.代码编写 1.所有定时任务的枚举(后期使用这个枚举来进行定时任务的增删改查) 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.freemud.enums;import com.freemud.extend.QuartzJobExtend;import com.freemud.quartz.CancelOrderSyncQuartz;import com.freemud.quartz.HrLinkSyncQuartz;import com.freemud.quartz.OrderSyncQuartz;import lombok.Getter;import org.springframework.util.StringUtils;@Getterpublic enum QuartzJobEnum { PULL_ORDER(1, OrderSyncQuartz.class), CANCEL_ORDER(2, CancelOrderSyncQuartz.class), HR_SYNC(3, HrLinkSyncQuartz.class), ; private Integer code; private Class&lt;? extends QuartzJobExtend&gt; clazz; QuartzJobEnum(Integer code, Class clazz) { this.code = code; this.clazz = clazz; } public static QuartzJobEnum getByCodeOrClassName(Integer code, String className) { if (code != null) { for (QuartzJobEnum value : values()) { if (value.getCode() == code) { return value; } } } if (!StringUtils.isEmpty(className)) { for (QuartzJobEnum value : values()) { if (className.equals(value.getClazz().getSimpleName())) { return value; } } } return null; }} 2.扩展下定时任务,由于没有特别的规范要求,因此这里假设 JobName默认是类的简称 GroupName默认是全称 任务描述由实现类进行说明 123456789101112131415161718192021package com.freemud.extend;import org.springframework.scheduling.quartz.QuartzJobBean;public abstract class QuartzJobExtend extends QuartzJobBean { public String getJobName() { return getClass().getSimpleName(); } public String getJobGroupName() { return getClass().getName(); } public abstract String getJobDescription(); public String getTriggerDescription() { return getJobDescription() + &quot;trigger&quot;; }} 3.定时任务 123456789101112@Component@Configuration@EnableScheduling@Slf4jpublic class CancelOrderSyncQuartz extends QuartzJobExtend { @Scheduled(cron = &quot;0 0/1 * * * ? &quot;) protected void executeQuartz() { //do something } } 改为: 1234567891011121314151617181920@Component@Configuration@EnableScheduling@Slf4jpublic class CancelOrderSyncQuartz extends QuartzJobExtend { protected void executeQuartz() { //do something } @Override public String getJobDescription() { return &quot;取消时同步定时任务&quot;; } @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { executeQuartz(); }} 至此定时任务已经正常在使用了; 但是如何初始化定时任务,如何在项目运行期间暂停/修改定时任务执行频率需要优化一下: 4.定时任务的增删改查 直接上代码; 修改定时任务同新增放在一个地方: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137package com.freemud.service;import com.freemud.commonbase.utils.SpringUtils;import com.freemud.commonbase.vo.ScheduleAddVo;import com.freemud.commonbase.vo.ScheduleDeleteVo;import com.freemud.entity.response.ScheduleResponseVo;import com.freemud.enums.QuartzJobEnum;import com.freemud.extend.QuartzJobExtend;import com.google.common.collect.Sets;import lombok.extern.slf4j.Slf4j;import org.quartz.*;import org.quartz.impl.matchers.GroupMatcher;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.util.CollectionUtils;import java.util.ArrayList;import java.util.List;import java.util.Set;@Slf4j@Servicepublic class ScheduleService { @Autowired private Scheduler scheduler; public void addSchedule(ScheduleAddVo scheduleAddVo) throws SchedulerException { QuartzJobEnum jobEnum = QuartzJobEnum.getByCodeOrClassName( scheduleAddVo.getCode(), scheduleAddVo.getClassName()); if (jobEnum == null) { return; } QuartzJobExtend jobExtend = SpringUtils.getBean(jobEnum.getClazz()); TriggerKey triggerKey = TriggerKey.triggerKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); CronTrigger cronTrigger = TriggerBuilder.newTrigger() .withIdentity(triggerKey) .withDescription(jobExtend.getJobDescription()) .withSchedule( CronScheduleBuilder.cronSchedule(scheduleAddVo.getCornExpressoin()) .withMisfireHandlingInstructionDoNothing() ).build(); //进行更新操作 if (scheduler.checkExists(triggerKey)) { JobKey jobKey = new JobKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); JobDetail jobDetail = scheduler.getJobDetail(jobKey); jobDetail.getJobBuilder().withDescription(jobExtend.getJobDescription()); scheduler.scheduleJob(jobDetail, Sets.newHashSet(cronTrigger), true); }else{ //执行新增操作 JobDetail jobDetail = JobBuilder.newJob(jobExtend.getClass()) .withDescription(jobExtend.getJobDescription()) .withIdentity(jobExtend.getJobName(), jobExtend.getJobGroupName()) .build(); scheduler.scheduleJob(jobDetail, cronTrigger); } } public void deleteSchedule(ScheduleDeleteVo scheduleDeleteVo) throws SchedulerException { QuartzJobEnum jobEnum = QuartzJobEnum.getByCodeOrClassName( scheduleDeleteVo.getCode(), scheduleDeleteVo.getClassName()); if (jobEnum == null) { return; } QuartzJobExtend jobExtend = SpringUtils.getBean(jobEnum.getClazz()); TriggerKey triggerKey = TriggerKey.triggerKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); if (scheduler.checkExists(triggerKey)) { scheduler.pauseTrigger(triggerKey); scheduler.unscheduleJob(triggerKey); } } public List&lt;ScheduleResponseVo&gt; listAllSchedule() throws SchedulerException { List&lt;ScheduleResponseVo&gt; result = new ArrayList&lt;&gt;(); List&lt;String&gt; jobGroupNames = scheduler.getJobGroupNames(); if (CollectionUtils.isEmpty(jobGroupNames)) { return result; } for (String jobGroupName : jobGroupNames) { Set&lt;JobKey&gt; jobKeySet = scheduler.getJobKeys(GroupMatcher.jobGroupEquals(jobGroupName)); if (CollectionUtils.isEmpty(jobKeySet)) { continue; } for (JobKey jobKey : jobKeySet) { ScheduleResponseVo responseVo = new ScheduleResponseVo(); JobDetail jobDetail = scheduler.getJobDetail(jobKey); TriggerKey triggerKey = TriggerKey.triggerKey(jobKey.getName(), jobGroupName); Trigger trigger = scheduler.getTrigger(triggerKey); ScheduleResponseVo.JobDetail jobDetailResponse = responseVo.new JobDetail(); jobDetailResponse.setJobName(jobKey.getName()); jobDetailResponse.setJobClass(jobDetail.getJobClass().getName()); jobDetailResponse.setJobGroupName(jobGroupName); jobDetailResponse.setDescription(jobDetail.getDescription()); responseVo.setJobDetail(jobDetailResponse); ScheduleResponseVo.Trigger triggerResponse = responseVo.new Trigger(); triggerResponse.setDescription(trigger.getDescription()); triggerResponse.setStartTime(trigger.getStartTime()); triggerResponse.setNextTime(trigger.getNextFireTime()); if (trigger instanceof CronTrigger) { CronTrigger cronTrigger = (CronTrigger) trigger; triggerResponse.setCornExpression(cronTrigger.getCronExpression()); triggerResponse.setExpressionSummary(cronTrigger.getExpressionSummary()); } Trigger.TriggerState triggerState = scheduler.getTriggerState(triggerKey); triggerResponse.setStatus(triggerState.toString()); responseVo.setTrigger(triggerResponse); result.add(responseVo); } } return result; } public void pauseSchedule(Integer code) throws SchedulerException { QuartzJobEnum quartzJobEnum = QuartzJobEnum.getByCodeOrClassName(code, null); QuartzJobExtend jobExtend = SpringUtils.getBean(quartzJobEnum.getClazz()); TriggerKey triggerKey = TriggerKey.triggerKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); if (scheduler.checkExists(triggerKey)) { scheduler.pauseTrigger(triggerKey); } }} 查询定时任务时返回的实体类如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.freemud.entity.response;import lombok.Data;import java.util.Date;@Datapublic class ScheduleResponseVo { private JobDetail jobDetail; private Trigger trigger; @Data public class JobDetail { private String jobName; private String jobGroupName; private String jobClass; private String description; } @Data public class Trigger { private String cornExpression; private String expressionSummary; private String description; private Date startTime; private Date nextTime; private String status; }} 然后在controller中进行调用即可; 1234567891011121314151617181920212223242526272829303132@RestController@RequestMapping(&quot;/schedule&quot;)public class ScheduleController { @Autowired private ScheduleService scheduleService; @PostMapping(&quot;/add&quot;) public BaseResponse addSchedule(@RequestBody ScheduleAddVo scheduleAddVo) throws SchedulerException { scheduleService.addSchedule(scheduleAddVo); return ResponseUtil.success(); } @DeleteMapping public BaseResponse deleteSchedule(@RequestBody ScheduleDeleteVo scheduleDeleteVo) throws SchedulerException { scheduleService.deleteSchedule(scheduleDeleteVo); return ResponseUtil.success(); } @GetMapping public BaseResponse getSchedule() throws SchedulerException { return ResponseUtil.success(scheduleService.listAllSchedule()); } @PostMapping(&quot;/pause/{code}&quot;) public BaseResponse pauseSchedule(@PathVariable Integer code) throws SchedulerException { scheduleService.pauseSchedule(code); return ResponseUtil.success(); }} - 新增(同修改)时通过传入code或者类名来进行设置定时任务的执行如: 1234{ &quot;code&quot;: 2, &quot;cornExpressoin&quot; : &quot;0 */1 * * * ?&quot;} - 查询的效果: 1234567891011121314151617181920212223242526272829303132333435363738{ &quot;code&quot;: 100, &quot;msg&quot;: &quot;success&quot;, &quot;data&quot;: [ { &quot;jobDetail&quot;: { &quot;jobName&quot;: &quot;CancelOrderSyncQuartz$$EnhancerBySpringCGLIB$$df76ceae&quot;, &quot;jobGroupName&quot;: &quot;com.freemud.quartz.CancelOrderSyncQuartz$$EnhancerBySpringCGLIB$$df76ceae&quot;, &quot;jobClass&quot;: &quot;com.freemud.quartz.CancelOrderSyncQuartz$$EnhancerBySpringCGLIB$$df76ceae&quot;, &quot;description&quot;: &quot;取消同步&quot; }, &quot;trigger&quot;: { &quot;cornExpression&quot;: &quot;*/5 * * * * ?&quot;, &quot;expressionSummary&quot;: &quot;seconds: 0,5,10,15,20,25,30,35,40,45,50,55\\nminutes: *\\nhours: *\\ndaysOfMonth: *\\nmonths: *\\ndaysOfWeek: ?\\nlastdayOfWeek: false\\nnearestWeekday: false\\nNthDayOfWeek: 0\\nlastdayOfMonth: false\\nyears: *\\n&quot;, &quot;description&quot;: &quot;取消同步&quot;, &quot;startTime&quot;: &quot;2020-11-11T05:41:16.000+0000&quot;, &quot;nextTime&quot;: &quot;2020-11-11T05:42:15.000+0000&quot;, &quot;status&quot;: &quot;NORMAL&quot; } }, { &quot;jobDetail&quot;: { &quot;jobName&quot;: &quot;OrderSyncQuartz&quot;, &quot;jobGroupName&quot;: &quot;com.freemud.quartz.OrderSyncQuartz&quot;, &quot;jobClass&quot;: &quot;com.freemud.quartz.OrderSyncQuartz&quot;, &quot;description&quot;: &quot;拉单定时任务&quot; }, &quot;trigger&quot;: { &quot;cornExpression&quot;: &quot;0 */1 * * * ?&quot;, &quot;expressionSummary&quot;: &quot;seconds: 0\\nminutes: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59\\nhours: *\\ndaysOfMonth: *\\nmonths: *\\ndaysOfWeek: ?\\nlastdayOfWeek: false\\nnearestWeekday: false\\nNthDayOfWeek: 0\\nlastdayOfMonth: false\\nyears: *\\n&quot;, &quot;description&quot;: &quot;拉单定时任务&quot;, &quot;startTime&quot;: &quot;2020-11-11T05:42:11.000+0000&quot;, &quot;nextTime&quot;: &quot;2020-11-11T05:43:00.000+0000&quot;, &quot;status&quot;: &quot;PAUSE&quot; } } ]}","link":"/2020/11/11/quartz%E4%BD%BF%E7%94%A8/"},{"title":"springretry","text":"spring出品,必定是精品 参考文章/连接 Java实现几种简单的重试机制 spring-retry 源码README.md spring-retry（1.概念和基本用法） 背景 项目之前有一段代码 123456789101112131415 public void syncPosByDelivery(DeliveryStatusDto dto, int retryNum) { try { if (retryNum &lt; 2) { Response response = retryThree(dto, System.currentTimeMillis()); if (!Objects.equals(response.code(), 204)) { Thread.sleep(5000L); retryNum++; syncPosByDelivery(dto, retryNum); } } } catch (InterruptedException e) { e.printStackTrace(); }} 代码实现了重试三次的功能; 现在需求是三方接口可能会有超时;如果超时就重试.上述代码虽然可以实现;但是我觉得实现方法不应该这么粗暴.上网搜到了Java实现几种简单的重试机制这篇文章后,准备选用spring-retry来实现我的功能 原因无它,因为这是spring出产的… 官方文档快速上手学习下 非注解使用 主要学习下基本概念; 主要是:RetryContext/*RetryPolicy/RecoveryCallback/RetryCallback 重试时间策略: 12345678910111213141516@Testpublic void springRetry1() throws Throwable { RetryTemplate retryTemplate = new RetryTemplate(); TimeoutRetryPolicy policy = new TimeoutRetryPolicy(); policy.setTimeout(3000L); retryTemplate.setRetryPolicy(policy); Object execute = retryTemplate.execute((RetryCallback&lt;Object, Throwable&gt;) context -&gt; { TimeUnit.SECONDS.sleep(1); throw new RuntimeException(); }); System.out.println(&quot;execute = &quot; + execute);} 增加重试后补偿12345678910111213141516171819@Testpublic void springRetry2() throws Throwable { RetryTemplate retryTemplate = new RetryTemplate(); TimeoutRetryPolicy policy = new TimeoutRetryPolicy(); policy.setTimeout(3000L); retryTemplate.setRetryPolicy(policy); Object execute = retryTemplate.execute((RetryCallback&lt;Object, Throwable&gt;) context -&gt; { TimeUnit.SECONDS.sleep(1); throw new RuntimeException(); }, context -&gt; { return &quot;recoveryCallBack&quot;; }); System.out.println(&quot;execute = &quot; + execute);} 重试次数策略 1234567891011121314151617181920 @Testpublic void springRetry3() throws Throwable { RetryTemplate build = RetryTemplate.builder() .maxAttempts(3) //执行的时间执行 .fixedBackoff(1000) .retryOn(IllegalArgumentException.class) .build(); Object execute = build.execute(context -&gt; { // business logic here throw new RuntimeException(); }, (RecoveryCallback&lt;Object&gt;) context -&gt; { // recover logic here return &quot;111&quot;; }); System.out.println(&quot;execute = &quot; + execute);} 重试次数策略2: 12345678910111213141516171819202122232425 @Testpublic void springRetry4(){ RetryTemplate retryTemplate = new RetryTemplate(); SimpleRetryPolicy simpleRetryPolicy = new SimpleRetryPolicy(3, Collections.singletonMap(SocketTimeoutException.class, true)); retryTemplate.setRetryPolicy(simpleRetryPolicy); FixedBackOffPolicy backOffPolicy = new FixedBackOffPolicy(); backOffPolicy.setBackOffPeriod(1000L); retryTemplate.setBackOffPolicy(backOffPolicy); RetryContext execute = null; try { execute = retryTemplate.execute(context -&gt; { RetryContextCache retryContextCache = new MapRetryContextCache(); retryContextCache.put(&quot;eee&quot;, context); throw new RuntimeException(&quot;&quot;); }); } catch (RuntimeException e) { System.out.println(&quot;ExceptionUtils.getFullExceptionLine(e) = &quot; + ExceptionUtils.getFullExceptionLine(e)); } System.out.println(&quot;execute = &quot; + execute);} 注解使用 和非注解使用特别相同;然后按照文档上又额外学习下listener的使用 12345678910111213141516171819202122232425262728293031323334353637383940//自定义的listener @Beanpublic RetryListener retryListerner1() { return new RetryListener() { @Override public &lt;T, E extends Throwable&gt; boolean open(RetryContext context, RetryCallback&lt;T, E&gt; callback) { log.info(&quot;open &quot;); logAttributeName(&quot;open&quot;, context); return true; } @Override public &lt;T, E extends Throwable&gt; void close(RetryContext context, RetryCallback&lt;T, E&gt; callback, Throwable throwable) { log.info(&quot;close&quot;); logAttributeName(&quot;close&quot;,context); } @Override public &lt;T, E extends Throwable&gt; void onError(RetryContext context, RetryCallback&lt;T, E&gt; callback, Throwable throwable) { log.info(&quot;onError&quot;); logAttributeName(&quot;onError&quot;, context); } };}public static void logAttributeName(String methodName,RetryContext retryContext) { log.info(&quot;methodName : {} start&quot;, methodName); log.info(&quot;retryName : &quot; + retryContext.getAttribute(RetryContext.NAME)); for (String attributeName : retryContext.attributeNames()) { log.info(attributeName + &quot;: &quot; + retryContext.getAttribute(attributeName)); } log.info(&quot;methodName : {} end&quot;, methodName);}@Beanpublic RetryListener retryListerner2(){ return new StatisticsListener(new DefaultStatisticsRepository());} listener是用于接收到每次重试不同状态的通知;源码中默认应该是实例中的retryListerner2 注解使用 123456@Retryable(listeners = &quot;retryListerner1&quot;, maxAttempts = 2, backoff = @Backoff(delay = 100, maxDelay = 500)) public void retry() throws BaseException { throw new BaseException(&quot;retry&quot;); } 看一下listerner的调用顺序以及retryContext有哪些属性 1234567891011121314151617181920212223242526272829 23:08:19.928 test_project [] WARN o.s.r.policy.ExpressionRetryPolicy - #{...} syntax is not required for this run-time expression and is deprecated in favor of a simple expression string23:08:19.959 test_project [] INFO c.w.d.t.config.RetryConfig - open 23:08:19.959 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : open start23:08:19.960 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : null23:08:19.960 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : open end23:08:19.970 test_project [] INFO c.w.d.t.config.RetryConfig - onError23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError start23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError end23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - onError23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError start23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError end23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - onError23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError start23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError end23:08:21.990 test_project [] INFO c.w.d.t.service.RetryService - -----------------------23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - close23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : close start23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.exhausted: true23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.recovered: true23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.closed: true23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : close end 加入recover使用123456789@Retryable(recover = &quot;recover&quot;, value = BaseException.class)public void retryRecover() { throw new BaseException(&quot;retry&quot;);}@Recoverpublic void recover(BaseException e) { log.info(&quot;-----------------------&quot;);} spel表达式:官方文档中指出在注解中可以使用spel表达式; 如下:12345678910111213141516@Retryable(exceptionExpression=&quot;message.contains('this can be retried')&quot;)public void service1() { ...}@Retryable(exceptionExpression=&quot;message.contains('this can be retried')&quot;)public void service2() { ...}@Retryable(exceptionExpression=&quot;@exceptionChecker.shouldRetry(#root)&quot;, maxAttemptsExpression = &quot;#{@integerFiveBean}&quot;, backoff = @Backoff(delayExpression = &quot;#{1}&quot;, maxDelayExpression = &quot;#{5}&quot;, multiplierExpression = &quot;#{1.1}&quot;))public void service3() { ...} 之前对表达式没有深入了解到,因此下面exceptionChecker.shouldRetry(#root)这一个看不懂; 不知道是不是大多数人都知道…总之我百度不出来,然后看了下spel表达式后简单解释下上面的用例: 1234message.contains('this can be retried') -&gt; 假设抛出异常为e;那么e.getMessage().contains('this can be retried')@exceptionChecker.shouldRetry(#root) -&gt;有一个name为exceptionChecker的bean; bean中有一个方法为shoudRetry;入参是是这个异常本身 注意 : 其他代码可以cv; 如果上面那个代码直接cv是会抛出spel相关Exception;如果坚持使用;请加入下面代码1234567891011121314151617public static class ExceptionChecker { public boolean shouldRetry(Throwable t) { return true; }} //并在项目中引入该bean;@Beanpublic ExceptionChecker exceptionChecker() { return new ExceptionChecker();} //同理可得 integerFiveBean也是一个bean@Beanpublic Integer integerFiveBean() { return Integer.valueOf(5);} 配置文件中加入其他变量","link":"/2020/10/28/springretry/"},{"title":"typora使用","text":"安利下 typora 这个markdown编辑工具 界面简洁,功能强大 对于普通的markdown语法不在描述,不过我迷上了写流程图,为什么是写流程图不是画,是因为真的就是写出来的图 直接上用例 时序图1234567891011sequenceDiagramloop 定时任务达美乐tracker系统 -&gt;&gt; 聚合服务 : 拉单(外送单)end聚合服务 -&gt;&gt; 聚合服务 : 通过mq实现延迟推送聚合服务 -&gt;&gt; 配送服务: 推单配送服务 -&gt;&gt; 配送服务: 自配送配送服务 -&gt;&gt; 顺丰服务 : 推送运单顺丰服务 --&gt;&gt; 配送服务 : 状态回调配送服务 --&gt;&gt; 聚合服务 : 状态回调聚合服务 --&gt;&gt; 达美乐plus系统 : plus回报 对应的实际效果图: 来自我们产品漂亮的时序图1234567891011121314151617181920212223242526272829303132333435363738sequenceDiagram顾客-&gt;&gt;tracker: 下单loop 正向流程配送系统-&gt;&gt;tracker: 一分钟拉取一次订单tracker--&gt;&gt;配送系统: 拉取到`存餐状态`订单配送系统-&gt;&gt;tracker: 一分钟拉取一次订单，获取`取餐码`、`取餐柜订单号`、`柜号`tracker--&gt;&gt;配送系统: 返回配送系统-&gt;&gt;骑手APP: 信鸽推送`取餐码`、`取餐柜订单号`和`柜号`骑手APP-&gt;&gt;配送系统: 一键取餐配送系统-&gt;&gt;东城: 拿`取餐柜订单号`、`验签信息`开柜取餐（接口：`5. 远程开箱`）东城--&gt;&gt;配送系统:取餐成功配送系统--&gt;&gt;骑手APP: 更新取餐状态（取餐成功，置灰）配送系统-&gt;&gt;配送系统: 第三方骑手接单，获取骑手手机号配送系统-&gt;&gt;EC短信平台: 短信推送`取餐码`和`柜号`给第三方骑手手机号EC短信平台-&gt;&gt;第三方骑手:通知`取餐码`、`柜号`第三方骑手-&gt;&gt;东城:拿`取餐码`取餐loop 线下的东城校验流程东城--&gt;&gt;东城:拿`取餐码`开柜取餐，返回成功与否end东城--&gt;&gt;第三方骑手:开柜成功&amp;失败endloop 逆向流程tracker--&gt;&gt;配送系统: 拉取到`取消存餐状态`订单配送系统-&gt;&gt;EC短信平台: 短信通知给第三方骑手手机号EC短信平台-&gt;&gt;第三方骑手:通知骑手取消存餐配送系统-&gt;&gt;骑手APP: 信鸽推送取消存餐，一键取餐按钮置灰骑手APP-&gt;&gt;配送系统: 一键取餐（停留在订单页面未离开）配送系统--&gt;&gt;东城: 拿`取餐柜订单号`、`验签信息`开柜取餐（接口：`5. 远程开箱`）东城--&gt;&gt;配送系统:取餐失败配送系统--&gt;&gt;骑手APP: 取餐失败，更新按钮`置灰`endloop 补偿流程骑手APP-&gt;&gt;配送系统:开始配送配送系统--&gt;&gt;配送系统: 判断当前批次已`一键取餐`配送系统--&gt;&gt;骑手APP: 开始配送成功，当前批次进入配送中配送系统--&gt;&gt;配送系统: 判断当前批次有运单未`一键取餐`配送系统--&gt;&gt;骑手APP: 开始配送失败，提示：`还有订单未取餐，请先取餐`end 实际效果(图太大,截不了全图,可以自己试试): 流程图1234567891011graph TD新运单 --&gt; 首次分配首次分配 -- 空闲骑手 --&gt; FIRST[直接分配] --&gt; 结束首次分配 -- 待单数之内 --&gt; 创建新的批次或者并单 --&gt; 结束首次分配 -- 待单数之外 --&gt; 顺丰 -- 配送方案最长接单时间 --&gt; 取消创建新运单推送自配送--空闲骑手--&gt; SECOND[直接分配]--&gt; 结束取消创建新运单推送自配送 -- 可以并单 --&gt; 直接并入批次--&gt; 结束取消创建新运单推送自配送 -- 不可以并单 --&gt; 创建新的批次 --&gt; 结束 这张图确实丑了点,嗯,我现在还不熟练,但是这个流程称得上很清晰了","link":"/2020/11/20/typora%E4%BD%BF%E7%94%A8/"},{"title":"双数据源实现方式二-区分包扫描方式","text":"[toc] 包扫描方式 上文写到的第一种方法aop没有切到父类方法,解决方法也有多种;可以百度搜下; 这篇文章的方案是: 不同的包对应不同的数据源 ; 这种访问的重点就是配置.配置只要对了; 就很简单 step1:配置datasource/mapperscanner/sqlsessionfactory注意将原先的@MapperScan注解干掉,下面会自定义 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Bean(&quot;sqlServerDS&quot;)@Primary@ConfigurationProperties(prefix = &quot;sqlserver.datasource&quot;)public DataSource sqlServerDS() { return DataSourceBuilder.create().type(HikariDataSource.class).build();}@Bean(&quot;mysqlDS&quot;)@ConfigurationProperties(prefix = &quot;mysql.datasource&quot;)public DataSource mysqlDS() { return DataSourceBuilder.create().type(HikariDataSource.class).build();}@Primary@Beanpublic SqlSessionFactory sqlServerSqlSessionFactory(@Qualifier(&quot;sqlServerDS&quot;) DataSource dataSource) throws Exception { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(dataSource); return factoryBean.getObject();}@Beanpublic SqlSessionFactory mysqlSqlSessionFactory(@Qualifier(&quot;mysqlDS&quot;) DataSource dataSource) throws Exception { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(dataSource); return factoryBean.getObject();}@Beanpublic MapperScannerConfigurer sqlServerMapperScanner() { MapperScannerConfigurer sqlServerMapperScanner = new MapperScannerConfigurer(); sqlServerMapperScanner.setSqlSessionFactoryBeanName(&quot;sqlServerSqlSessionFactory&quot;); sqlServerMapperScanner.setBasePackage(&quot;com.freemud.order.dao.sqlserver&quot;); Properties properties = new Properties(); properties.setProperty(&quot;mappers&quot;, Mapper.class.getName()); properties.setProperty(&quot;notEmpty&quot;, &quot;false&quot;); properties.setProperty(&quot;IDENTITY&quot;, &quot;SqlServer&quot;); sqlServerMapperScanner.setProperties(properties); return sqlServerMapperScanner;}@Beanpublic MapperScannerConfigurer mysqlMapperScanner() { MapperScannerConfigurer sqlServerMapperScanner = new MapperScannerConfigurer(); sqlServerMapperScanner.setSqlSessionFactoryBeanName(&quot;mysqlSqlSessionFactory&quot;); sqlServerMapperScanner.setBasePackage(&quot;com.freemud.order.dao.mysql&quot;); Properties properties = new Properties(); properties.setProperty(&quot;mappers&quot;, Mapper.class.getName()); properties.setProperty(&quot;notEmpty&quot;, &quot;false&quot;); properties.setProperty(&quot;IDENTITY&quot;, &quot;MySQL&quot;); sqlServerMapperScanner.setProperties(properties); return sqlServerMapperScanner;} step2: 整理自己的代码分层比如将原先的dao 分为dao.mysql; 和dao.sqlserver; 不同的数据源对应不同的包这样子 step3: 代码使用本次使用的场景是数据库逐步迁移; 因此做了黑白名单,默认sqlserver; 上了名单走mysql 123456789public BaseResponse queryOrderListByTime(OrderVo vo) { List&lt;? extends OrderDto&gt; orderDtos ; if (vo.getDsTypeEnum() == DSTypeEnum.SQLSERVER) { orderDtos = orderDao.selectByOrderVo(vo); }else{ orderDtos = mySqlOrderDao.selectByOrderVo(vo); } return ResponseUtil.success(orderDtos); } 注意事项 不同的datasource的配置略有不同,比如durid的是url; 而HikariDataSource是jdbc-url 项目中原先的@MapperScan要干掉; MapperScannerConfigurer这个要注意; 因为代码有一定演示意义在内,实际中如果你继承的不是Mapper;而是自定义的需要加到这里面; 多个就用逗号隔开","link":"/2020/11/20/%E5%8F%8C%E6%95%B0%E6%8D%AE%E6%BA%90%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E4%BA%8C-%E5%8C%BA%E5%88%86%E5%8C%85%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/"},{"title":"双数据源实现方式一-注解方式","text":"注解+aop 先把个人的结论写前面 通过aop + 注解的形式在切面切换数据源实现 优势: 对本身的代码分层没有任何变化.即两个数据源对应的entity/repository不变 劣势: aop切父类方法会失效;即:如果使用通用mapper则会导致父类方法没切到 通过不同数据源扫描不同的包实现 优势: 只关心实体类对应包即可,不需要额外增加注解 劣势:有一定的侵入; 比如原本dao在repository包下,现在需要再建一个;比如原先的迁移到dao.primary包下; 第二数据源放在dao.second包下 第一种方式: aop+注解流程效果 : 调用repository层方法前;通过切面切换数据源; 直接撸代码 step1 增加注解:因为一个repository类不应该同时对应两个数据库; 应该注解指定定义类使用即可 12345678@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value = {ElementType.TYPE})public @interface DataSourceType { DBTypeEnum value() default DBTypeEnum.PRIMARY;} 同时定义下两种不同数据源的枚举 12345678910@Getterpublic enum DBTypeEnum { PRIMARY(&quot;primaryDb&quot;), LOG(&quot;logDb&quot;),; private String dbName; DBTypeEnum(String dbName) { this.dbName = dbName; }} step2 动态数据源123456789spring.datasource.druid.url=jdbc:mysql://127.0.0.1:3306/sharding_0?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=UTCspring.datasource.druid.username=rootspring.datasource.druid.password=rootspring.datasource.druid.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.log.url=jdbc:mysql://127.0.0.1:3306/sharding_1?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=UTCspring.datasource.log.username=rootspring.datasource.log.password=rootspring.datasource.log.driver-class-name=com.mysql.cj.jdbc.Driver 1234567891011121314151617181920212223242526272829303132333435@Bean@Primary@ConfigurationProperties(&quot;spring.datasource.druid&quot;)public DataSource primaryDb() { return DruidDataSourceBuilder.create().build();}@Bean@ConfigurationProperties(&quot;spring.datasource.log&quot;)public DataSource logDb() { return DruidDataSourceBuilder.create().build();}@Beanpublic DynamicDataSource dynamicDataSource(@Qualifier(&quot;primaryDb&quot;) DataSource primaryDb, @Qualifier(&quot;logDb&quot;) DataSource logDb) { Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(DBTypeEnum.PRIMARY, primaryDb); targetDataSources.put(DBTypeEnum.LOG, logDb); return new DynamicDataSource(primaryDb, targetDataSources);}/** * 低版本中SqlSessionFactory会自动注入; 高版本取消了sqlsessionfactory的自动注入; 需要自己手动注入 * @param dynamicDataSource * @return * @throws Exception */@Beanpublic SqlSessionFactory sqlSessionFactory(DynamicDataSource dynamicDataSource) throws Exception { final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(dynamicDataSource); return sessionFactory.getObject();} 123456789101112131415161718192021public class DynamicDataSource extends AbstractRoutingDataSource { private static final ThreadLocal&lt;DBTypeEnum&gt; DB_HOLDER = new ThreadLocal&lt;&gt;(); public DynamicDataSource(DataSource defaultTargetDataSource, Map&lt;Object, Object&gt; targetDataSource) { super.setDefaultTargetDataSource(defaultTargetDataSource); super.setTargetDataSources(targetDataSource); super.afterPropertiesSet(); } @Override protected Object determineCurrentLookupKey() { return DB_HOLDER.get(); } public static void setDBType(DBTypeEnum dbType) { DB_HOLDER.set(dbType); } public static DBTypeEnum getDBType() { return DB_HOLDER.get(); } public static void clearDBType() { DB_HOLDER.remove(); }} step3 定义aop1234567891011121314@Before(value = &quot;execution(* com.daily.multipledatasource01.repository..*.*(..))&quot;) public void doBefore(JoinPoint joinPoint) { Class targetClass = joinPoint.getSignature().getDeclaringType(); DataSourceType annotation = AnnotationUtils.findAnnotation(targetClass, DataSourceType.class); if (annotation != null) { DynamicDataSource.setDBType(annotation.value()); } } @After(value = &quot;execution(* com.daily.multipledatasource01.repository..*.*(..))&quot;) public void doAfter(JoinPoint joinPoint) { DynamicDataSource.clearDBType(); } step4 代码使用父类方法的接口没有切到,所以暂时先写一个新的方法跑通流程 123456@DataSourceType(DBTypeEnum.LOG)public interface OrderLogRepository extends Mapper&lt;OrderLog&gt; { default int save(OrderLog orderLog) { return insert(orderLog); }}","link":"/2020/11/20/%E5%8F%8C%E6%95%B0%E6%8D%AE%E6%BA%90%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E4%B8%80-%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F/"},{"title":"延时队列的不同实现形式","text":"将死信队列升级为延时队列 客户的数据不推送到我们服务中,创建配送单的方式是手动拉他们的数据创建配送单;门店有一个制作时间,因此会设置一个延迟推送时间(可配置); 如下单6分钟后该创建该运单的配送单 历史做法 创建一个定时任务; 1分钟拉取一次数据; 将符合条件的数据设置超时时间放到一个无消费者的队列中 队列延时时间到了之后, 丢入死信队列中 死信队列的消费者会先查该运单是否创建过(因为6分钟可能被拉取到6次); 如果没有创建过则创建一条运单 改造原因(主要还是第二条) 1.上述提到的6分钟可配置; 由于是一个定制化商户;这个商户曾连续修改这个值;已经有了延迟1,3,5,6,7,8,9,10,15,30,60这么多延时的死信队列了; 还提出有新的延迟时间 2.逻辑已经上线N个月了; 我刚接手一个月说这个时间不准确; 延迟6分钟; 但是他们看到的是超过了6分钟多了几秒; 感觉在欺负我一样 3.代码太乱了; 因为每一个延迟时间就创建两个队列; 在声明的类中代码太长;接手就发现7分钟的延迟对了用的是五分钟的配置.查问题不好查 改造方式1(客户需要配合) 要求: 1.mq版本升级到3.6以上 (项目已支持)2.安装动态延迟队列插件: rabbitmq_delayed_message_exchange 实现 创建队列1234567891011121314151617 @Bean CustomExchange multipleDelayExchange(){ Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(&quot;x-delayed-type&quot;, &quot;direct&quot;); return new CustomExchange(DELAY_EXCHANGE, &quot;x-delayed-message&quot;, true, false, args); } @Bean Queue multipleDelayQueue() { return new Queue(DELAY_QUEUE, true); } @Bean Binding multipleDelayBinding() { return BindingBuilder.bind(multipleDelayQueue()) .to(multipleDelayExchange()) .with(DELAY_ROUTING) .noargs(); } 消费者12345 @RabbitListener(queues = MultiplexDlConfig.DELAY_QUEUE) public void consumer(String msg, Message message) { log.info(&quot;当前时间: {} ,message : {} &quot;, LocalDateTime.now(), message); } 发送端123456789101112 @PostMapping(&quot;/send&quot;) public ResponseEntity&lt;String&gt; multipleDlSendMsg(@RequestBody MultipleDlRequest multipleDlRequest) { rabbitTemplate.convertAndSend(MultiplexDlConfig.DELAY_EXCHANGE, MultiplexDlConfig.DELAY_ROUTING, multipleDlRequest.getMessage(), msg -&gt; { log.info(&quot;当前时间: {} ,msg : {} &quot;, LocalDateTime.now(), msg); Integer delayTime = multipleDlRequest.getDlTime() * 1000; msg.getMessageProperties().setHeader(&quot;x-delay&quot;, delayTime); return msg; }); return ResponseEntity.ok(&quot;ok&quot;); } 方式2(客户不配合) 客户要是配合的话也不会出现定时拉取他们数据这种情况, 所以上面的是主要方案; 这个是备选方案 参考地址:有赞延迟队列设计demo已经写过; 对于wait/notify因为需求又来了一批;回头尝试下 总结下延迟队列的实现形式 不考虑延时的实时性; 使用定时任务+死信队列 使用mq延时队列 redis的zset来实现延时队列","link":"/2020/09/27/%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/"},{"title":"hexo","text":"hexo学习 参考博客如下: hexo从零开始到搭建完整 hexo史上最全搭建教程 技术小白搭建个人博客 github+hexo 写博客常用命令 hexo Docs 博客本地启动: hexo s = hexo server 本地创建一个新的页面: hexo new [title] 写完之后生成静态文件: hexo g = hexo generate 提交到远程git上: hexo d = hero deploy 主题修改根据上面的搭建博客后; 因为太丑,因此网上查下哪款主题比较好看 作为一个审美并不强的人,在一个非官方的统计中,icarus排名第一我并不是一个特别纠结的人; 在都不认识的情况下,我选择第一名,即时不是最佳,也一定不会差, 主题并不算复杂;但是有一篇文章写得挺好,可能在版本上有点久(新版本使用的react);但是借鉴意义我感觉特别好 Hexo+icarus主题配置","link":"/2020/09/25/hexo/"},{"title":"hexo多台电脑","text":"多台电脑的博客同步 一般来说,我们写博客不会只在一台电脑上使用,比如公司一台电脑家里一台电脑 在比如我,我在家是用台式电脑的, 这样就会有三台电脑,我可以控制在一台电脑上使用,但是明显能够在三台电脑上都能够写文章是最佳的,因此需要三台电脑进行同步 方案一这种方案最简单,也最差劲 将自己本地的文件进行拷贝;然后再第二台电脑上安装好hexo和node.js环境后,你就可以再第二台电脑上写自己的博文 但是这样子你之前的文章你需要一直的进行拷贝;明显不符合我们的需求,这种情况只适用于有一台电脑,刚好要换一台电脑的情况(但是如果电脑崩溃了…那就彻底没了) 方案二将自己的东西放到互联网上,这样子可以比较好的防止自己的东西丢失; 这个我是将自己的文件放到了git上; github支持创建私有仓库,但是我hexo上没有隐私的账号之类的东西,因此我选择与博客放在一个repository进行管理,步骤如下: 创建一个分支,比如hexo 本地clone 切换分支到hexo中 git checkout hexo 当我们执行hexo g后,hexo是将文件放在了public文件夹下,而我们执行hexo d也是将public文件下的东西上传到gitub上去,所以我们现在需要将上一级也就是public文件这一级的文件上传到hexo分支中来; 因此先将所有文件进行删除 如果你的文件夹是展示隐藏文件的话,不要删除掉.git文件 将hexo的文件夹拷贝到当前目录,然后上传到github上 git add . git commit -m ‘hexo init’ git push 如果你选择了主题,当你执行git add .时,并没有将所有文件添加到git进行管理,因为这时候你的主题文件夹下也有一个.git文件.这时候我们需要将主题不交于git管理,比如我使用的theme是icarus;操作如下 cd theme/icarus git status - 查看下当前的分支;我这边是默认的origin git remote rm origin 这时候与远程将不再有关系,再删除文件下的.git文件(可能直接删除也可以,不过我是先解除了远程的绑定) 如果没有找到.git;就在查看中展示隐藏文件(.git默认是隐藏文件) 重新执行上面的git add .;然后进行提交 这时候我们的hexo相关的文件都在git上进行了托管;当我们切换电脑/或者在另一台电脑上使用时.只需要在父目录下git pull一下就可以同步我们的文件 最后:如果不希望自己的源文件被别人看到; 可以用相同的办法上传到一个private的repository中","link":"/2020/11/28/hexo%E5%A4%9A%E5%8F%B0%E7%94%B5%E8%84%91/"},{"title":"MYSQL文档翻译(一)","text":"尝试联系下读英文文档的能力; 刚好准备梳理下mysql的explain;就从这里开始吧 文档来源 8.8.1 Optimizing Queries with EXPLAIN 1使用explain来是优化查询 The EXPLAIN statement provides information about how MySQL executes statements: 1explain会提供mysql是如何执行sql语句的 EXPLAIN works with SELECT, DELETE, INSERT, REPLACE, and UPDATE statements. 1explain 工作与 insert/update/replace/delete/select When EXPLAIN is used with an explainable statement, MySQL displays information from the optimizer about the statement execution plan. That is, MySQL explains how it would process the statement, including information about how tables are joined and in which order. For information about using EXPLAIN to obtain execution plan information, see Section 8.8.2, “EXPLAIN Output Format”. 12345当explain被使用解释一次sql语句;mysql会展示出这次查询最优方案的执行计划,这就代表.mysql会解释它自身是如何执行这个查询;包括表之间关联和顺序;更多关于如何使用explain来获取执行计划的信息,可以看8.8.2章节, &quot;解释器输出格式&quot; When EXPLAIN is used with FOR CONNECTION connection_id rather than an explainable statement, it displays the execution plan for the statement executing in the named connection. See Section 8.8.4, “Obtaining Execution Plan Information for a Named Connection”. 123当explain不是用于解释这次查询而是被用于一个链接的链接id;他会展示关于这次查询连接的执行计划,可以看8.8.4章节&quot;获取连接的执行计划信息&quot; For SELECT statements, EXPLAIN produces additional execution plan information that can be displayed using SHOW WARNINGS. See Section 8.8.3, “Extended EXPLAIN Output Format”. 123使用select 语句时; explain提供了额外的执行计划信息会展示告警信息;可以看8.8.3章节; '扩展解释输出格式' EXPLAIN is useful for examining queries involving partitioned tables. See Section 21.3.5, “Obtaining Information About Partitions”. 12explain在测试分区的表的查询时是很有帮助的,具体可以看21.3.5章节, &quot;获取分区的更多信息&quot; The FORMAT option can be used to select the output format. TRADITIONAL presents the output in tabular format. This is the default if no FORMAT option is present. JSON format displays the information in JSON format. 1234FORMAT分类可以可以被用于查询输出格式, TRADITIONAL展示了输出的表输出格式;如果没有设置FORMAT的值会使用默认值; JSON的格式化会列出JSON格式化的信息 With the help of EXPLAIN, you can see where you should add indexes to tables so that the statement executes faster by using indexes to find rows. You can also use EXPLAIN to check whether the optimizer joins the tables in an optimal order. To give a hint to the optimizer to use a join order corresponding to the order in which the tables are named in a SELECT statement, begin the statement with SELECT STRAIGHT_JOIN rather than just SELECT. (See Section 13.2.9, “SELECT Statement”.) However, STRAIGHT_JOIN may prevent indexes from being used because it disables semijoin transformations. See Section 8.2.2.1, “Optimizing Subqueries, Derived Tables, and View References with Semijoin Transformations”. 1234567通过explain的帮助, 你可以看你是否有给表增加索引,以此查看语句执行速度通过使用索引来查找数据变快了; 你同样可以使用explain来校验表关联的最优排序;会给出select语句中会给出最优关联顺序的提示;是使用select直接关联而不是仅仅使用select(详情查看13.2.9,查询语句); 然而; 直接关联可能会避免了索引的使用因为它禁用半连接转化; 详情看8.2.2.1&quot;获取子查询,表渠道,显示半连接的依赖&quot; The optimizer trace may sometimes provide information complementary to that of EXPLAIN. However, the optimizer trace format and content are subject to change between versions. For details, see MySQL Internals: Tracing the Optimizer. 123获取最优链路有时候提供提供了一些信息与explain会进行互补; 然而最优链路格式和内容会随着版本进行变更;更多信息,可以查看mysql的网站: 获取链路追踪 If you have a problem with indexes not being used when you believe that they should be, run ANALYZE TABLE to update table statistics, such as cardinalityof keys, that can affect the choices the optimizer makes. See Section 13.7.2.1, “ANALYZE TABLE Statement”. 123如果你有一些使用索引的问题是你不确定它是否应该被使用; 你可以执行表分析来更新表统计结果;比如键可以影响调优的选择,可以看章节:13.7.2.1&quot;分析表语句&quot; NoteEXPLAIN can also be used to obtain information about the columns in a table. EXPLAIN tbl_name is synonymous with DESCRIBE tbl_name and SHOW COLUMNS FROM tbl_name. For more information, see Section 13.8.1, “DESCRIBE Statement”, and Section 13.7.5.5, “SHOW COLUMNS Statement”. 1234注意:explain同样被用于获取表的每一行的信息;explain一个表名和describe一个表名是相同的意思都会展示表的每一行; 更多信息可以看13.8.1章节&quot;描述语句&quot;和13.7.5.5章节,&quot;显示语句的行数&quot; 没有认识英文如下: semijoin :半连接 corresponding : adj.符合的; 相应的; 相关的; complementary: 互补 cardinality: 基数","link":"/2020/11/30/MYSQL%E6%96%87%E6%A1%A3%E7%BF%BB%E8%AF%91(%E4%B8%80)/"},{"title":"MYSQL文档翻译(二)","text":"文档来源: EXPLAIN OUTPUT FORMAT 8.8.2 EXPLAIN Output FormatThe EXPLAIN statement provides information about how MySQL executes statements. EXPLAIN works with SELECT, DELETE, INSERT, REPLACE, and UPDATE statements. 12执行器提供了mysql执行语句的信息, 执行器工作与`查询`,`删除`,`插入`,`替换`和`更新`语句 EXPLAIN returns a row of information for each table used in the SELECT statement. It lists the tables in the output in the order that MySQL would read them while processing the statement. MySQL resolves all joins using a nested-loop join method. This means that MySQL reads a row from the first table, and then finds a matching row in the second table, the third table, and so on. When all tables are processed, MySQL outputs the selected columns and backtracks through the table list until a table is found for which there are more matching rows. The next row is read from this table and the process continues with the next table. 12345678在查询语句中,执行器会返回一行信息关于被使用到的每一张表,执行语句时,会根据这些表的集合在mysql中的顺序进行读取;mysql使用`嵌套循环`方法来拆分解析所有的关联; 这就意味着mysql会先读取第一张表的一行数据,然后找到和这一列匹配的第二个表数据,然后是第三个,以此类推;当所有的表都被执行了;mysql会输出这次查询的列并且通过这个表的集合回退栈知道找到匹配的这些列;下一行从这张表中读取,然后继续执行下一张表 EXPLAIN output includes partition information. Also, for SELECT statements, EXPLAIN generates extended information that can be displayed with SHOW WARNINGS following the EXPLAIN (see Section 8.8.3, “Extended EXPLAIN Output Format”). 123执行器的数据包括分区信息;并且对于查询语句,解析器会生成扩展信息,扩展信息会展示告警信息;详情请看8.8.3章,解析器输出扩展 Note In older MySQL releases, partition and extended information was produced using EXPLAIN PARTITIONS and EXPLAIN EXTENDED. Those syntaxes are still recognized for backward compatibility but partition and extended output is now enabled by default, so the PARTITIONS and EXTENDED keywords are superfluous and deprecated. Their use results in a warning; expect them to be removed from EXPLAIN syntax in a future MySQL release. 12345另外最老的mysql发行版中,分区和扩展信息是通过使用EXPLAIN PARTITIONS和EXPLAIN EXTENDED来生效的;这些语法现在依旧能够兼容但是分区和扩展输出现在默认是开启的;所以 分区和扩展 关键字是多余的并且不推荐使用的; 使用他们再结果中会出现告警,期望值是将来的mysql发行版能够去除该语法 You cannot use the deprecated PARTITIONS and EXTENDED keywords together in the same EXPLAIN statement. In addition, neither of these keywords can be used together with the FORMAT option. 12不能和在执行器预期中同时使用不被推荐使用的分区和扩展的关键字; 另外,这些关键字任何一个都不能和format选项一起使用 Note MySQL Workbench has a Visual Explain capability that provides a visual representation of EXPLAIN output. See Tutorial: Using Explain to Improve Query Performance. EXPLAIN Output Columns EXPLAIN Join Types EXPLAIN Extra Information EXPLAIN Output Interpretation 1234567注意:mysql控制台有可视化执行能力,用于提供执行器输出的可视化的表现,这部分可以看关于使用执行计划来提升查询优化的导航部分:- 执行计划会输出那些列- 执行计划关联分类- 执行计划额外信息- 执行计划输出解释 不认识英文: nested-loop join 这个当时想翻译成 网状循环 的; 后来查了下这是一种数据库中常用的算法 superfluous: 多余的 capability: 功能;能力 representation:表现;代表 Interpretation: 解释;说明","link":"/2020/12/01/MYSQL%E6%96%87%E6%A1%A3%E7%BF%BB%E8%AF%91(%E4%BA%8C)/"},{"title":"数据库索引导致的生产事故","text":"可以看前几篇博客中我正在学习mysql官方文档的explain.结果就碰到了因为索引导致的生产事故,记录一下 服务配送服务 前提专门为一个大的客户提供了一套完整的自配送规则流程,但是接手后发现有很多表都没有加索引.因此来了一次系统的搜查,将重要表的查询/更新加了索引;但是因为做报表的一个加标记的sql没有检查到,而客户刚好搞活动,大批量的请求进来后,直接导致C端疯狂报错,骑手无法正常使用APP本次事故出现了两次 第一次根据日志排查的原因是服务器与数据库的链接被占满了; 调整链接后恢复 第二天有一次出现日志提示大量的sql回滚,排查原因是表被锁了,增加索引后恢复 感想 服务要提前做好配置的检查 更新sql如果条件不走索引会引起锁整个表,因此特别是更新语句一定要全部排查(当然查询的也要增加索引) 第一天(周六)前提: 第一天的解决方案在第二天被证实没有完全解决 异常上报 骑手无法登陆app(持续20分钟后自动回复) 排查过程Step1: 确认下服务问题因为该服务近期未发版,突然出现大量请求有问题,需要确认是否服务器出现问题 结果: 沟通后没有抖动 Step2: 查日志 上报异常的接口部分请求的响应时间较长证实服务器确实存在问题 监控显示今天的单量是昨天的一倍多,前天的三倍 查error报错日志如下 12345### Error querying database. Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Failed to obtain JDBC Connection; nested exception is com.alibaba.druid.pool.GetConnectionTimeoutException: wait millis 10000, active 20, maxActive 20, creating 0, runningSqlCount 20 :update rider_delivery_time set arrival_time = now() 123456freemud-delivery-riderapp-service [http-nio-9050-exec-54]WARN o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Resolved [org.springframework.http.converter.HttpMessageNotReadableException:I/O error while reading input message; nested exception is java.io.EOFException: Unexpected EOF read on the socket] 无慢sql Step3: 目前服务器的配置12345678910111213141516171819#druidspring.datasource.initialSize=1spring.datasource.minIdle=1spring.datasource.maxActive=20spring.datasource.maxWait=10000#配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.timeBetweenEvictionRunsMillis=60000#配置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.minEvictableIdleTimeMillis=300000spring.datasource.testWhileIdle=truespring.datasource.testOnBorrow=truespring.datasource.testOnReturn=false#打开PSCache，并且指定每个连接上PSCache的大小spring.datasource.poolPreparedStatements=truespring.datasource.maxPoolPreparedStatementPerConnectionSize=20#配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙spring.datasource.filters=stat#通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 12345678910&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.11&lt;/version&gt;&lt;/dependency&gt; Step4:解决方案 修改durid版本到1.1.14版本(下一个就是1.2.*大版本; 紧急修复并没有升级最新的版本) 修改mysql的链接数 第二天(周日)异常上报 骑手点击开始配送或者配送完成时会卡住 排查过程step1:服务的日志和其他排查123456ERROR c.f.framework.log.ErrorLogConvert - appName:delivery-riderapp-service methodName:com.freemud.delivery.riderapp.controller.RiderController.backShoptrackingNo:8319095b02ef47cd8aa81954ce0a6e6c message:error_url/rider/backshop startTime:1607226762446 endTime:1607226762446 request:[{&quot;latitude&quot;:31.254941,&quot;longitude&quot;:121.419907,&quot;operateSource&quot;:0,&quot;riderId&quot;:&quot;01992fc3008c4db78e8d064e9c1751f4&quot;}] errorMsg:org.springframework.dao.RecoverableDataAccessException: 123456freemud-delivery-riderapp-service [http-nio-9050-exec-54]WARN o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver - Resolved [org.springframework.http.converter.HttpMessageNotReadableException: I/O error while reading input message;nested exception is java.io.EOFException:Unexpected EOF read on the socket] 12311:35:28.131 freemud-delivery-riderapp-service [http-nio-9050-exec-71] ERROR c.f.d.aop.GlobalExceptionHandler - org.springframework.dao.CannotAcquireLockException: step2: 问题追踪与db沟通CannotAcquireLockException的原因; db反馈有一个sql会锁表: 12update rider_delivery_time set arrival_time = now() where depatch_id = 'ff57f300c75d4f7f9feb step3:问题原因确认:由于需求变更,更新使用的字段发生了变更,原先的条件是走索引的;现在的where 条件没有索引,导致该表被锁住; 后续请求都发生了情况 另: 服务实际上已经多天未发版,由于突然客户的单量提升导致了问题的暴露 Step4:问题解决 db将当前被锁的进程kill掉;然后加索引紧急修复 上班后对系统的数据库操作sql检查;特别是更新语句; 防止update导致锁表 总结 公司的基础jar包使用时最好自己有一个大概的了解,公司封装的jar也经常会有一些bug; 服务的配置要关注下,之前写代码的人可能是大牛,也可能是新手;特别是默认配置,会随着业务量的提升出现瓶颈,需要及时调整优化 出现问题elk的error总是能最快的定位问题 索引一定要加;特别是更新条件中,没有索引会导致锁表","link":"/2020/12/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%AF%BC%E8%87%B4%E7%9A%84%E7%94%9F%E4%BA%A7%E4%BA%8B%E6%95%85/"}],"tags":[{"name":"quartz","slug":"quartz","link":"/tags/quartz/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"mq","slug":"mq","link":"/tags/mq/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"retry","slug":"retry","link":"/tags/retry/"},{"name":"日志链路追踪","slug":"日志链路追踪","link":"/tags/%E6%97%A5%E5%BF%97%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"explain","slug":"explain","link":"/tags/explain/"}],"categories":[{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"定时任务","slug":"定时任务","link":"/categories/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"中间介","slug":"中间介","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%8B/"},{"name":"英译汉","slug":"英译汉","link":"/categories/%E8%8B%B1%E8%AF%91%E6%B1%89/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"}]}