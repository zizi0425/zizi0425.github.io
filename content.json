{"pages":[],"posts":[{"title":"ControllerAdvice失效","text":"jar包和本地冲突,不想使用jar包的解决方案 接手了一个项目, 整个项目没有使用过自定义异常, 自己加入了全局异常无效 自己加入的全局异常如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.freemud.delivery.aop;import com.freemud.delivery.entity.enums.ResultCodeEnum;import com.freemud.delivery.entity.exception.DeliveryException;import com.freemud.delivery.entity.util.ExceptionUtils;import com.freemud.delivery.entity.vo.ApiResult;import lombok.extern.slf4j.Slf4j;import org.springframework.validation.ObjectError;import org.springframework.web.bind.MethodArgumentNotValidException;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.RestControllerAdvice;import java.util.List;import java.util.stream.Collectors;@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler { @ExceptionHandler({MethodArgumentNotValidException.class}) public ApiResult handler(MethodArgumentNotValidException e) { List&lt;String&gt; errorList = e.getBindingResult().getAllErrors() .stream() .map(ObjectError::getDefaultMessage) .map(String::valueOf) .collect(Collectors.toList()); return new ApiResult(ResultCodeEnum.PARAM_ERROR, errorList); } @ExceptionHandler({DeliveryException.class}) public ApiResult handler(DeliveryException e) { return new ApiResult(e.getCode(), e.getMessage(), null); } @ExceptionHandler({Exception.class}) public ApiResult handler(Exception e) { log.error(ExceptionUtils.getFullStackTrace(e)); return new ApiResult(ResultCodeEnum.SYSTEM_ERROR); }} 使用时发现并没有生效,当我故意入参错误时,报错如下: 122020-11-06 17:51:51,113 WARN deliverycenter (AbstractHandlerExceptionResolver.java:140) Resolved [org.springframework.web.bind.MethodArgumentNotValidException: Validation failed for argument at index 0 in method: public com.freemud.delivery.entity.vo.ApiResult&lt;com.freemud.delivery.entity.vo.PageResult&lt;com.freemud.delivery.entity.vo.service.delivery.DeliveryVO&gt;&gt; com.freemud.delivery.service.controller.QueryDeliveryController.queryListByDeliveryStatus(com.freemud.delivery.entity.vo.service.delivery.QueryDeliveryListReqVO), with 1 error(s): [Field error in object 'queryDeliveryListReqVO' on field 'partnerId': rejected value []; codes [NotBlank.queryDeliveryListReqVO.partnerId,NotBlank.partnerId,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [queryDeliveryListReqVO.partnerId,partnerId]; arguments []; default message [partnerId]]; default message [partnerId不能为空]] ] 我在console中搜索我的这个bean时发现这个提示: 122020-11-06 17:55:52,459 INFO deliverycenter (ExceptionHandlerExceptionResolver.java:288) Detected @ExceptionHandler methods in platformExceptionHandler2020-11-06 17:55:52,459 INFO deliverycenter (ExceptionHandlerExceptionResolver.java:288) Detected @ExceptionHandler methods in globalExceptionHandler 原来这个服务引入了公司的一个基础包; 这个包里已经有了全局异常; 这个类如下: 123456789101112131415161718192021222324252627282930//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package com.freemud.framework.exception;import com.freemud.framework.constants.SysStatusCode;import com.freemud.framework.result.ApiResult;import com.freemud.framework.util.Utils;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;@ControllerAdvice@ResponseBodypublic class PlatformExceptionHandler { public PlatformExceptionHandler() { } @ExceptionHandler({Exception.class}) public ApiResult handleException() { return new ApiResult(SysStatusCode.SYSTEM_ERROR); } @ExceptionHandler({PlatformException.class}) public ApiResult handlePlatformException(PlatformException platformException) { return Utils.notNull(platformException.getCode()) ? new ApiResult(platformException.getCode(), platformException.getMsg()) : new ApiResult(SysStatusCode.SYSTEM_ERROR); }} 我认为这个全局异常处理太差劲了; 完全没办法满足我( 同时我有点不理解了,原来是有自定义异常类的; 但是整个项目从来没有见到过一个使用的地方) 所以我现在需要做的事情就是让基础jar包的失效,使用我自己的全局异常处理 这时候在SpringBoot启动类中的排除这一个bean的注入,代码如下: 12345@ComponentScan(value = &quot;com.free.*&quot;, excludeFilters = @ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, classes = {PlatformExceptionHandler.class} )) 重启服务,调试成功","link":"/2020/11/06/ControllerAdvice%E5%A4%B1%E6%95%88/"},{"title":"git网站","text":"如果想使用好git;那么git的命令一定是要使用的; 一直使用idea自带的并不能让自己完全熟悉git 整理下git的学习网站 网址 网站描述 https://git-scm.com/book/zh/v2 git 官网教程 https://www.zhihu.com/question/29929269 知乎的一篇推荐 https://learngitbranching.js.org git learning 图文教程 https://github.com/k88hudson/git-flight-rules/blob/master/README_zh-CN.md git flight rules https://www.jianshu.com/p/964de879904a commit 合并 https://segmentfault.com/a/1190000009048911 git commit 提交规范","link":"/2020/10/15/git/"},{"title":"log打印时增加链路id","text":"为mq服务生成一个trackingNo 前提 在使用分布式项目中,一个用户的一次请求应该是一条链路,当需要查找日志时, 可以根据一个id来将用户在所有子模块中的流程都获取到, 这时候在两个服务之间需要传递这个id(后面称它为tid). 然后在日志打印中将tid输出,elk搜集到后,通过tid就可以查到所有日志; 现在在查看问题的时候发现mq是没有这个tid的,因此自己加入到项目中,便于之后日志查询 ---- 实际中如果发送mq的地方有tid可以加入到mq的header中;在aop中获取该tid 熟悉下aopspringboot的版本12345-- springboot的版本为id 'org.springframework.boot' version '2.3.2.RELEASE'-- aop需要引入implementation 'org.springframework.boot:spring-boot-starter-aop' 开始测试aop各个注解对应的执行顺序 验证的注解: @Before @After @Around @AfterThrowing @AfterReturning 测试代码切面1234567891011121314151617181920212223242526272829303132333435363738@Aspect@Componentpublic class TrackingNoAop {// 在项目中实际使用注解时启动报错,发现需要使用全路径,可能是公司项目包版本低的原因,不多深究// @Pointcut(&quot;@annotation(TIDLog)&quot;) @Pointcut(&quot;execution(* com.wyj.daily.test_project.controller..*.*(..))&quot;) public void aspTrackingNo(){ } //2 @Before(&quot;aspTrackingNo()&quot;) public void before(JoinPoint joinPoint) { System.out.println(&quot;before&quot;); } //4 @After(&quot;aspTrackingNo()&quot;) public void after() { System.out.println(&quot;after&quot;); } //1 @Around(&quot;aspTrackingNo()&quot;) public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(&quot;around&quot;); Object proceed = proceedingJoinPoint.proceed(proceedingJoinPoint.getArgs()); System.out.println(&quot;proceed = &quot; + proceed); } //3 @AfterThrowing(pointcut = &quot;aspTrackingNo()&quot;, throwing = &quot;e&quot;) public void afterThrowing(JoinPoint joinPoint, Exception e) { System.out.println(&quot;afterThrowing&quot;); } //3 @AfterReturning(pointcut = &quot;aspTrackingNo()&quot;) public void afterReturning() { System.out.println(&quot;afterReturning &quot;); }} 被切的类1234567@GetMapping(&quot;/testAop/{type}&quot;)public ResponseEntity&lt;String&gt; testAop(@PathVariable Integer type) { if (type == 1) { throw new RuntimeException(); } return ResponseEntity.ok(&quot;哈哈&quot;);} 正常时打印12345aroundbeforeafterReturning afterproceed = &lt;200 OK OK,哈哈,[]&gt; 抛异常时打印1234aroundbeforeafterThrowingafter 结论:请求-&gt; around开始 -&gt; before -&gt; 执行方法(proceed)-&gt; afterThrowing/afterReturning -&gt;after -&gt; around 结束 代码非mq的时候(公司之前封装的)tid的本地线程变量:1234567891011121314151617181920public class LogTreadLocal { private static final ThreadLocal&lt;String&gt; trackingNoThreadLocal = new ThreadLocal(); public LogTreadLocal() { } public static void setTrackingNo(String trackingNo) { trackingNoThreadLocal.set(trackingNo); } public static String getTrackingNo() { String trackNo = (String)trackingNoThreadLocal.get(); return trackNo; } public static void removeTrackingNo() { trackingNoThreadLocal.remove(); }} 拦截器12345678910111213141516171819public class LogTrackNoInterceptor implements HandlerInterceptor { public LogTrackNoInterceptor() { } //假设两个服务之前会传递的这个值放在header中,name为:x-transaction-id public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) { LogTreadLocal.setTrackingNo(StringUtils.isEmpty(httpServletRequest.getHeader(&quot;x-transaction-id&quot;)) ? UUID.randomUUID().toString().replaceAll(&quot;-&quot;, &quot;&quot;) : httpServletRequest.getHeader(&quot;x-transaction-id&quot;)); return true; } public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) { } public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) { LogTreadLocal.removeTrackingNo(); }} 日志打印时输入tid即可本次调整关于mq消费者的日志打印原本熟悉切面后,也准备放入本地线程变量中,但是公司使用logback进行日志打印, logback中有一个MDC功能,本质上也是本地线程变量,因此准备直接使用logback的MDC, 两者也不存在冲突 注解1234@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface TIDLog {} 切面12345678910111213141516171819202122232425262728@Aspect@Component@Slf4jpublic class TrackingNoAop { @Pointcut(&quot;@annotation(com.freemud.delivery.annotation.TIDLog)&quot;) public void trackingNo() { } //2 @Before(&quot;trackingNo()&quot;) public void before(JoinPoint joinPoint) { MDC.put(&quot;tid&quot;, UUIDUtils.getUUID()); } @After(&quot;trackingNo()&quot;) public void after() { MDC.remove(&quot;tid&quot;); } @AfterThrowing(pointcut = &quot;trackingNo()&quot;, throwing = &quot;e&quot;) public void afterThrowing(Exception e) { log.error(ExceptionUtils.getFullStackOnLine(e)); }} logback调整appender-&gt;encoder-&gt;pattern下增加该tid打印,比如: &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%X{tid}] %-5level %logger{36} - %msg%n&lt;/pattern&gt; ​ 新增日志打印工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Slf4jpublic class LogUtils { public static BiFunction&lt;Long, Long, Long&gt; takeUpTime = (startTime, endTime) -&gt; { if (startTime != null &amp;&amp; endTime != null) { return endTime - startTime; } return null; }; public static void info(String message, Object requestData, Object responseData) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.info(&quot;ClassName: {} ,MethodName: {} , MethodLine: {}, Message: {} , RequestData: {} ,ResponseData: {}&quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), message, JSONObject.toJSONString(requestData), JSONObject.toJSONString(responseData) ); } public static void info(String message, Object requestData, Object responseData, Long startTime, Long endTime) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.info(&quot;ClassName: {} ,MethodName: {} , MethodLine: {} , startTime: {} , takeUpTime: {}&quot; + &quot;, Message: {} , RequestData: {} ,ResponseData: {} &quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), startTime, takeUpTime.apply(startTime, endTime), message, JSONObject.toJSONString(requestData), JSONObject.toJSONString(responseData) ); } public static void error(String message, Object requestData, Exception e) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.error(&quot;ClassName: {} ,MethodName: {} , MethodLine: {}, Message: {} , RequestData: {} ,ExceptionInfo: {}&quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), message, JSONObject.toJSONString(requestData), ExceptionUtils.getFullStackTrace(e) ); } public static void error(String message, Object requestData, Long startTime, Long endTime, Exception e) { StackTraceElement stackTraceElement = Thread.currentThread().getStackTrace()[2]; log.error(&quot;ClassName: {} ,MethodName: {} , MethodLine: {}, startTime: {} , takeUpTime: {} ,&quot; + &quot; Message: {} , RequestData: {} , ExceptionInfo: {} , &quot;, stackTraceElement.getClassName(), stackTraceElement.getMethodName(), stackTraceElement.getLineNumber(), message, JSONObject.toJSONString(requestData), startTime, takeUpTime.apply(startTime, endTime), ExceptionUtils.getFullStackTrace(e) ); }}","link":"/2020/10/21/log%E6%89%93%E5%8D%B0%E6%97%B6%E5%A2%9E%E5%8A%A0%E9%93%BE%E8%B7%AFid/"},{"title":"quartz使用","text":"优先使用xxljob;条件不允许再考虑quartz 背景​ 有一个ka项目的定时任务服务是单节点,而这个明显是不合理的,准备搞成支持分布式的定时任务,第一个想到的xxljob;但是由于项目是运行在别人公司的服务器上,身不由己,最终选择使用quartz来进行定时任务的管理 效果​ 因为quartz是没有界面的; 之前的公司甚至见过通过查库来增加定时任务,因此希望实现的效果就是能够通过接口来对定时任务进行增删改查(界面是不可能的,只能接口了),功能如下: 新增定时任务 修改定时任务的corn表达式 暂停一个定时任务 删除一个定时任务 查询所有定时任务的列表 除此之外,我并不想太多的动之前的代码,因此尽量调整量小一些 流程 1.引包 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt; &lt;/dependency&gt; 2.建表语句: 不要百度,因为quartz1.0和2.0建表不一样; 不同数据库也可能有一些差别, 建表语句在github上quartz.core包的resource下,可以先看下项目引用的版本再到github上切换对应的版本上找自己使用的数据库初始化语句,最新master分支建表的位置 3.代码编写 1.所有定时任务的枚举(后期使用这个枚举来进行定时任务的增删改查) 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.freemud.enums;import com.freemud.extend.QuartzJobExtend;import com.freemud.quartz.CancelOrderSyncQuartz;import com.freemud.quartz.HrLinkSyncQuartz;import com.freemud.quartz.OrderSyncQuartz;import lombok.Getter;import org.springframework.util.StringUtils;@Getterpublic enum QuartzJobEnum { PULL_ORDER(1, OrderSyncQuartz.class), CANCEL_ORDER(2, CancelOrderSyncQuartz.class), HR_SYNC(3, HrLinkSyncQuartz.class), ; private Integer code; private Class&lt;? extends QuartzJobExtend&gt; clazz; QuartzJobEnum(Integer code, Class clazz) { this.code = code; this.clazz = clazz; } public static QuartzJobEnum getByCodeOrClassName(Integer code, String className) { if (code != null) { for (QuartzJobEnum value : values()) { if (value.getCode() == code) { return value; } } } if (!StringUtils.isEmpty(className)) { for (QuartzJobEnum value : values()) { if (className.equals(value.getClazz().getSimpleName())) { return value; } } } return null; }} 2.扩展下定时任务,由于没有特别的规范要求,因此这里假设 JobName默认是类的简称 GroupName默认是全称 任务描述由实现类进行说明 123456789101112131415161718192021package com.freemud.extend;import org.springframework.scheduling.quartz.QuartzJobBean;public abstract class QuartzJobExtend extends QuartzJobBean { public String getJobName() { return getClass().getSimpleName(); } public String getJobGroupName() { return getClass().getName(); } public abstract String getJobDescription(); public String getTriggerDescription() { return getJobDescription() + &quot;trigger&quot;; }} 3.定时任务 123456789101112@Component@Configuration@EnableScheduling@Slf4jpublic class CancelOrderSyncQuartz extends QuartzJobExtend { @Scheduled(cron = &quot;0 0/1 * * * ? &quot;) protected void executeQuartz() { //do something } } 改为: 1234567891011121314151617181920@Component@Configuration@EnableScheduling@Slf4jpublic class CancelOrderSyncQuartz extends QuartzJobExtend { protected void executeQuartz() { //do something } @Override public String getJobDescription() { return &quot;取消时同步定时任务&quot;; } @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { executeQuartz(); }} 至此定时任务已经正常在使用了; 但是如何初始化定时任务,如何在项目运行期间暂停/修改定时任务执行频率需要优化一下: 4.定时任务的增删改查 直接上代码; 修改定时任务同新增放在一个地方: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137package com.freemud.service;import com.freemud.commonbase.utils.SpringUtils;import com.freemud.commonbase.vo.ScheduleAddVo;import com.freemud.commonbase.vo.ScheduleDeleteVo;import com.freemud.entity.response.ScheduleResponseVo;import com.freemud.enums.QuartzJobEnum;import com.freemud.extend.QuartzJobExtend;import com.google.common.collect.Sets;import lombok.extern.slf4j.Slf4j;import org.quartz.*;import org.quartz.impl.matchers.GroupMatcher;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.util.CollectionUtils;import java.util.ArrayList;import java.util.List;import java.util.Set;@Slf4j@Servicepublic class ScheduleService { @Autowired private Scheduler scheduler; public void addSchedule(ScheduleAddVo scheduleAddVo) throws SchedulerException { QuartzJobEnum jobEnum = QuartzJobEnum.getByCodeOrClassName( scheduleAddVo.getCode(), scheduleAddVo.getClassName()); if (jobEnum == null) { return; } QuartzJobExtend jobExtend = SpringUtils.getBean(jobEnum.getClazz()); TriggerKey triggerKey = TriggerKey.triggerKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); CronTrigger cronTrigger = TriggerBuilder.newTrigger() .withIdentity(triggerKey) .withDescription(jobExtend.getJobDescription()) .withSchedule( CronScheduleBuilder.cronSchedule(scheduleAddVo.getCornExpressoin()) .withMisfireHandlingInstructionDoNothing() ).build(); //进行更新操作 if (scheduler.checkExists(triggerKey)) { JobKey jobKey = new JobKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); JobDetail jobDetail = scheduler.getJobDetail(jobKey); jobDetail.getJobBuilder().withDescription(jobExtend.getJobDescription()); scheduler.scheduleJob(jobDetail, Sets.newHashSet(cronTrigger), true); }else{ //执行新增操作 JobDetail jobDetail = JobBuilder.newJob(jobExtend.getClass()) .withDescription(jobExtend.getJobDescription()) .withIdentity(jobExtend.getJobName(), jobExtend.getJobGroupName()) .build(); scheduler.scheduleJob(jobDetail, cronTrigger); } } public void deleteSchedule(ScheduleDeleteVo scheduleDeleteVo) throws SchedulerException { QuartzJobEnum jobEnum = QuartzJobEnum.getByCodeOrClassName( scheduleDeleteVo.getCode(), scheduleDeleteVo.getClassName()); if (jobEnum == null) { return; } QuartzJobExtend jobExtend = SpringUtils.getBean(jobEnum.getClazz()); TriggerKey triggerKey = TriggerKey.triggerKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); if (scheduler.checkExists(triggerKey)) { scheduler.pauseTrigger(triggerKey); scheduler.unscheduleJob(triggerKey); } } public List&lt;ScheduleResponseVo&gt; listAllSchedule() throws SchedulerException { List&lt;ScheduleResponseVo&gt; result = new ArrayList&lt;&gt;(); List&lt;String&gt; jobGroupNames = scheduler.getJobGroupNames(); if (CollectionUtils.isEmpty(jobGroupNames)) { return result; } for (String jobGroupName : jobGroupNames) { Set&lt;JobKey&gt; jobKeySet = scheduler.getJobKeys(GroupMatcher.jobGroupEquals(jobGroupName)); if (CollectionUtils.isEmpty(jobKeySet)) { continue; } for (JobKey jobKey : jobKeySet) { ScheduleResponseVo responseVo = new ScheduleResponseVo(); JobDetail jobDetail = scheduler.getJobDetail(jobKey); TriggerKey triggerKey = TriggerKey.triggerKey(jobKey.getName(), jobGroupName); Trigger trigger = scheduler.getTrigger(triggerKey); ScheduleResponseVo.JobDetail jobDetailResponse = responseVo.new JobDetail(); jobDetailResponse.setJobName(jobKey.getName()); jobDetailResponse.setJobClass(jobDetail.getJobClass().getName()); jobDetailResponse.setJobGroupName(jobGroupName); jobDetailResponse.setDescription(jobDetail.getDescription()); responseVo.setJobDetail(jobDetailResponse); ScheduleResponseVo.Trigger triggerResponse = responseVo.new Trigger(); triggerResponse.setDescription(trigger.getDescription()); triggerResponse.setStartTime(trigger.getStartTime()); triggerResponse.setNextTime(trigger.getNextFireTime()); if (trigger instanceof CronTrigger) { CronTrigger cronTrigger = (CronTrigger) trigger; triggerResponse.setCornExpression(cronTrigger.getCronExpression()); triggerResponse.setExpressionSummary(cronTrigger.getExpressionSummary()); } Trigger.TriggerState triggerState = scheduler.getTriggerState(triggerKey); triggerResponse.setStatus(triggerState.toString()); responseVo.setTrigger(triggerResponse); result.add(responseVo); } } return result; } public void pauseSchedule(Integer code) throws SchedulerException { QuartzJobEnum quartzJobEnum = QuartzJobEnum.getByCodeOrClassName(code, null); QuartzJobExtend jobExtend = SpringUtils.getBean(quartzJobEnum.getClazz()); TriggerKey triggerKey = TriggerKey.triggerKey(jobExtend.getJobName(), jobExtend.getJobGroupName()); if (scheduler.checkExists(triggerKey)) { scheduler.pauseTrigger(triggerKey); } }} 查询定时任务时返回的实体类如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.freemud.entity.response;import lombok.Data;import java.util.Date;@Datapublic class ScheduleResponseVo { private JobDetail jobDetail; private Trigger trigger; @Data public class JobDetail { private String jobName; private String jobGroupName; private String jobClass; private String description; } @Data public class Trigger { private String cornExpression; private String expressionSummary; private String description; private Date startTime; private Date nextTime; private String status; }} 然后在controller中进行调用即可; 1234567891011121314151617181920212223242526272829303132@RestController@RequestMapping(&quot;/schedule&quot;)public class ScheduleController { @Autowired private ScheduleService scheduleService; @PostMapping(&quot;/add&quot;) public BaseResponse addSchedule(@RequestBody ScheduleAddVo scheduleAddVo) throws SchedulerException { scheduleService.addSchedule(scheduleAddVo); return ResponseUtil.success(); } @DeleteMapping public BaseResponse deleteSchedule(@RequestBody ScheduleDeleteVo scheduleDeleteVo) throws SchedulerException { scheduleService.deleteSchedule(scheduleDeleteVo); return ResponseUtil.success(); } @GetMapping public BaseResponse getSchedule() throws SchedulerException { return ResponseUtil.success(scheduleService.listAllSchedule()); } @PostMapping(&quot;/pause/{code}&quot;) public BaseResponse pauseSchedule(@PathVariable Integer code) throws SchedulerException { scheduleService.pauseSchedule(code); return ResponseUtil.success(); }} - 新增(同修改)时通过传入code或者类名来进行设置定时任务的执行如: 1234{ &quot;code&quot;: 2, &quot;cornExpressoin&quot; : &quot;0 */1 * * * ?&quot;} - 查询的效果: 1234567891011121314151617181920212223242526272829303132333435363738{ &quot;code&quot;: 100, &quot;msg&quot;: &quot;success&quot;, &quot;data&quot;: [ { &quot;jobDetail&quot;: { &quot;jobName&quot;: &quot;CancelOrderSyncQuartz$$EnhancerBySpringCGLIB$$df76ceae&quot;, &quot;jobGroupName&quot;: &quot;com.freemud.quartz.CancelOrderSyncQuartz$$EnhancerBySpringCGLIB$$df76ceae&quot;, &quot;jobClass&quot;: &quot;com.freemud.quartz.CancelOrderSyncQuartz$$EnhancerBySpringCGLIB$$df76ceae&quot;, &quot;description&quot;: &quot;取消同步&quot; }, &quot;trigger&quot;: { &quot;cornExpression&quot;: &quot;*/5 * * * * ?&quot;, &quot;expressionSummary&quot;: &quot;seconds: 0,5,10,15,20,25,30,35,40,45,50,55\\nminutes: *\\nhours: *\\ndaysOfMonth: *\\nmonths: *\\ndaysOfWeek: ?\\nlastdayOfWeek: false\\nnearestWeekday: false\\nNthDayOfWeek: 0\\nlastdayOfMonth: false\\nyears: *\\n&quot;, &quot;description&quot;: &quot;取消同步&quot;, &quot;startTime&quot;: &quot;2020-11-11T05:41:16.000+0000&quot;, &quot;nextTime&quot;: &quot;2020-11-11T05:42:15.000+0000&quot;, &quot;status&quot;: &quot;NORMAL&quot; } }, { &quot;jobDetail&quot;: { &quot;jobName&quot;: &quot;OrderSyncQuartz&quot;, &quot;jobGroupName&quot;: &quot;com.freemud.quartz.OrderSyncQuartz&quot;, &quot;jobClass&quot;: &quot;com.freemud.quartz.OrderSyncQuartz&quot;, &quot;description&quot;: &quot;拉单定时任务&quot; }, &quot;trigger&quot;: { &quot;cornExpression&quot;: &quot;0 */1 * * * ?&quot;, &quot;expressionSummary&quot;: &quot;seconds: 0\\nminutes: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59\\nhours: *\\ndaysOfMonth: *\\nmonths: *\\ndaysOfWeek: ?\\nlastdayOfWeek: false\\nnearestWeekday: false\\nNthDayOfWeek: 0\\nlastdayOfMonth: false\\nyears: *\\n&quot;, &quot;description&quot;: &quot;拉单定时任务&quot;, &quot;startTime&quot;: &quot;2020-11-11T05:42:11.000+0000&quot;, &quot;nextTime&quot;: &quot;2020-11-11T05:43:00.000+0000&quot;, &quot;status&quot;: &quot;PAUSE&quot; } } ]}","link":"/2020/11/11/quartz%E4%BD%BF%E7%94%A8/"},{"title":"springretry","text":"spring出品,必定是精品 参考文章/连接 Java实现几种简单的重试机制 spring-retry 源码README.md spring-retry（1.概念和基本用法） 背景 项目之前有一段代码 123456789101112131415 public void syncPosByDelivery(DeliveryStatusDto dto, int retryNum) { try { if (retryNum &lt; 2) { Response response = retryThree(dto, System.currentTimeMillis()); if (!Objects.equals(response.code(), 204)) { Thread.sleep(5000L); retryNum++; syncPosByDelivery(dto, retryNum); } } } catch (InterruptedException e) { e.printStackTrace(); }} 代码实现了重试三次的功能; 现在需求是三方接口可能会有超时;如果超时就重试.上述代码虽然可以实现;但是我觉得实现方法不应该这么粗暴.上网搜到了Java实现几种简单的重试机制这篇文章后,准备选用spring-retry来实现我的功能 原因无它,因为这是spring出产的… 官方文档快速上手学习下 非注解使用 主要学习下基本概念; 主要是:RetryContext/*RetryPolicy/RecoveryCallback/RetryCallback 重试时间策略: 12345678910111213141516@Testpublic void springRetry1() throws Throwable { RetryTemplate retryTemplate = new RetryTemplate(); TimeoutRetryPolicy policy = new TimeoutRetryPolicy(); policy.setTimeout(3000L); retryTemplate.setRetryPolicy(policy); Object execute = retryTemplate.execute((RetryCallback&lt;Object, Throwable&gt;) context -&gt; { TimeUnit.SECONDS.sleep(1); throw new RuntimeException(); }); System.out.println(&quot;execute = &quot; + execute);} 增加重试后补偿12345678910111213141516171819@Testpublic void springRetry2() throws Throwable { RetryTemplate retryTemplate = new RetryTemplate(); TimeoutRetryPolicy policy = new TimeoutRetryPolicy(); policy.setTimeout(3000L); retryTemplate.setRetryPolicy(policy); Object execute = retryTemplate.execute((RetryCallback&lt;Object, Throwable&gt;) context -&gt; { TimeUnit.SECONDS.sleep(1); throw new RuntimeException(); }, context -&gt; { return &quot;recoveryCallBack&quot;; }); System.out.println(&quot;execute = &quot; + execute);} 重试次数策略 1234567891011121314151617181920 @Testpublic void springRetry3() throws Throwable { RetryTemplate build = RetryTemplate.builder() .maxAttempts(3) //执行的时间执行 .fixedBackoff(1000) .retryOn(IllegalArgumentException.class) .build(); Object execute = build.execute(context -&gt; { // business logic here throw new RuntimeException(); }, (RecoveryCallback&lt;Object&gt;) context -&gt; { // recover logic here return &quot;111&quot;; }); System.out.println(&quot;execute = &quot; + execute);} 重试次数策略2: 12345678910111213141516171819202122232425 @Testpublic void springRetry4(){ RetryTemplate retryTemplate = new RetryTemplate(); SimpleRetryPolicy simpleRetryPolicy = new SimpleRetryPolicy(3, Collections.singletonMap(SocketTimeoutException.class, true)); retryTemplate.setRetryPolicy(simpleRetryPolicy); FixedBackOffPolicy backOffPolicy = new FixedBackOffPolicy(); backOffPolicy.setBackOffPeriod(1000L); retryTemplate.setBackOffPolicy(backOffPolicy); RetryContext execute = null; try { execute = retryTemplate.execute(context -&gt; { RetryContextCache retryContextCache = new MapRetryContextCache(); retryContextCache.put(&quot;eee&quot;, context); throw new RuntimeException(&quot;&quot;); }); } catch (RuntimeException e) { System.out.println(&quot;ExceptionUtils.getFullExceptionLine(e) = &quot; + ExceptionUtils.getFullExceptionLine(e)); } System.out.println(&quot;execute = &quot; + execute);} 注解使用 和非注解使用特别相同;然后按照文档上又额外学习下listener的使用 12345678910111213141516171819202122232425262728293031323334353637383940//自定义的listener @Beanpublic RetryListener retryListerner1() { return new RetryListener() { @Override public &lt;T, E extends Throwable&gt; boolean open(RetryContext context, RetryCallback&lt;T, E&gt; callback) { log.info(&quot;open &quot;); logAttributeName(&quot;open&quot;, context); return true; } @Override public &lt;T, E extends Throwable&gt; void close(RetryContext context, RetryCallback&lt;T, E&gt; callback, Throwable throwable) { log.info(&quot;close&quot;); logAttributeName(&quot;close&quot;,context); } @Override public &lt;T, E extends Throwable&gt; void onError(RetryContext context, RetryCallback&lt;T, E&gt; callback, Throwable throwable) { log.info(&quot;onError&quot;); logAttributeName(&quot;onError&quot;, context); } };}public static void logAttributeName(String methodName,RetryContext retryContext) { log.info(&quot;methodName : {} start&quot;, methodName); log.info(&quot;retryName : &quot; + retryContext.getAttribute(RetryContext.NAME)); for (String attributeName : retryContext.attributeNames()) { log.info(attributeName + &quot;: &quot; + retryContext.getAttribute(attributeName)); } log.info(&quot;methodName : {} end&quot;, methodName);}@Beanpublic RetryListener retryListerner2(){ return new StatisticsListener(new DefaultStatisticsRepository());} listener是用于接收到每次重试不同状态的通知;源码中默认应该是实例中的retryListerner2 注解使用 123456@Retryable(listeners = &quot;retryListerner1&quot;, maxAttempts = 2, backoff = @Backoff(delay = 100, maxDelay = 500)) public void retry() throws BaseException { throw new BaseException(&quot;retry&quot;); } 看一下listerner的调用顺序以及retryContext有哪些属性 1234567891011121314151617181920212223242526272829 23:08:19.928 test_project [] WARN o.s.r.policy.ExpressionRetryPolicy - #{...} syntax is not required for this run-time expression and is deprecated in favor of a simple expression string23:08:19.959 test_project [] INFO c.w.d.t.config.RetryConfig - open 23:08:19.959 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : open start23:08:19.960 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : null23:08:19.960 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : open end23:08:19.970 test_project [] INFO c.w.d.t.config.RetryConfig - onError23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError start23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:19.971 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError end23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - onError23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError start23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:20.988 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError end23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - onError23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError start23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : onError end23:08:21.990 test_project [] INFO c.w.d.t.service.RetryService - -----------------------23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - close23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : close start23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - retryName : public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.name: public void com.wyj.daily.test_project.service.RetryService.retryException() throws com.wyj.daily.commonbase.exception.BaseException23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.exhausted: true23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.recovered: true23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - context.closed: true23:08:21.990 test_project [] INFO c.w.d.t.config.RetryConfig - methodName : close end 加入recover使用123456789@Retryable(recover = &quot;recover&quot;, value = BaseException.class)public void retryRecover() { throw new BaseException(&quot;retry&quot;);}@Recoverpublic void recover(BaseException e) { log.info(&quot;-----------------------&quot;);} spel表达式:官方文档中指出在注解中可以使用spel表达式; 如下:12345678910111213141516@Retryable(exceptionExpression=&quot;message.contains('this can be retried')&quot;)public void service1() { ...}@Retryable(exceptionExpression=&quot;message.contains('this can be retried')&quot;)public void service2() { ...}@Retryable(exceptionExpression=&quot;@exceptionChecker.shouldRetry(#root)&quot;, maxAttemptsExpression = &quot;#{@integerFiveBean}&quot;, backoff = @Backoff(delayExpression = &quot;#{1}&quot;, maxDelayExpression = &quot;#{5}&quot;, multiplierExpression = &quot;#{1.1}&quot;))public void service3() { ...} 之前对表达式没有深入了解到,因此下面exceptionChecker.shouldRetry(#root)这一个看不懂; 不知道是不是大多数人都知道…总之我百度不出来,然后看了下spel表达式后简单解释下上面的用例: 1234message.contains('this can be retried') -&gt; 假设抛出异常为e;那么e.getMessage().contains('this can be retried')@exceptionChecker.shouldRetry(#root) -&gt;有一个name为exceptionChecker的bean; bean中有一个方法为shoudRetry;入参是是这个异常本身 注意 : 其他代码可以cv; 如果上面那个代码直接cv是会抛出spel相关Exception;如果坚持使用;请加入下面代码1234567891011121314151617public static class ExceptionChecker { public boolean shouldRetry(Throwable t) { return true; }} //并在项目中引入该bean;@Beanpublic ExceptionChecker exceptionChecker() { return new ExceptionChecker();} //同理可得 integerFiveBean也是一个bean@Beanpublic Integer integerFiveBean() { return Integer.valueOf(5);} 配置文件中加入其他变量","link":"/2020/10/28/springretry/"},{"title":"typora使用","text":"安利下 typora 这个markdown编辑工具 界面简洁,功能强大 对于普通的markdown语法不在描述,不过我迷上了写流程图,为什么是写流程图不是画,是因为真的就是写出来的图 直接上用例 时序图sequenceDiagram loop 定时任务 达美乐tracker系统 ->> 聚合服务 : 拉单(外送单) end 聚合服务 ->> 聚合服务 : 通过mq实现延迟推送 聚合服务 ->> 配送服务: 推单 配送服务 ->> 配送服务: 自配送 配送服务 ->> 顺丰服务 : 推送运单 顺丰服务 -->> 配送服务 : 状态回调 配送服务 -->> 聚合服务 : 状态回调 聚合服务 -->> 达美乐plus系统 : plus回报 对应的实际效果图: 来自我们产品漂亮的时序图sequenceDiagram 顾客->>tracker: 下单 loop 正向流程 配送系统->>tracker: 一分钟拉取一次订单 tracker-->>配送系统: 拉取到`存餐状态`订单 配送系统->>tracker: 一分钟拉取一次订单，获取`取餐码`、`取餐柜订单号`、`柜号` tracker-->>配送系统: 返回 配送系统->>骑手APP: 信鸽推送`取餐码`、`取餐柜订单号`和`柜号` 骑手APP->>配送系统: 一键取餐 配送系统->>东城: 拿`取餐柜订单号`、`验签信息`开柜取餐（接口：`5. 远程开箱`） 东城-->>配送系统:取餐成功 配送系统-->>骑手APP: 更新取餐状态（取餐成功，置灰） 配送系统->>配送系统: 第三方骑手接单，获取骑手手机号 配送系统->>EC短信平台: 短信推送`取餐码`和`柜号`给第三方骑手手机号 EC短信平台->>第三方骑手:通知`取餐码`、`柜号` 第三方骑手->>东城:拿`取餐码`取餐 loop 线下的东城校验流程 东城-->>东城:拿`取餐码`开柜取餐，返回成功与否 end 东城-->>第三方骑手:开柜成功&失败 end loop 逆向流程 tracker-->>配送系统: 拉取到`取消存餐状态`订单 配送系统->>EC短信平台: 短信通知给第三方骑手手机号 EC短信平台->>第三方骑手:通知骑手取消存餐 配送系统->>骑手APP: 信鸽推送取消存餐，一键取餐按钮置灰 骑手APP->>配送系统: 一键取餐（停留在订单页面未离开） 配送系统-->>东城: 拿`取餐柜订单号`、`验签信息`开柜取餐（接口：`5. 远程开箱`） 东城-->>配送系统:取餐失败 配送系统-->>骑手APP: 取餐失败，更新按钮`置灰` end loop 补偿流程 骑手APP->>配送系统:开始配送 配送系统-->>配送系统: 判断当前批次已`一键取餐` 配送系统-->>骑手APP: 开始配送成功，当前批次进入配送中 配送系统-->>配送系统: 判断当前批次有运单未`一键取餐` 配送系统-->>骑手APP: 开始配送失败，提示：`还有订单未取餐，请先取餐` end 实际效果(图太大,截不了全图,可以自己试试): 流程图 graph TD 新运单 --> 首次分配 首次分配 -- 空闲骑手 --> FIRST[直接分配] --> 结束 首次分配 -- 待单数之内 --> 创建新的批次或者并单 --> 结束 首次分配 -- 待单数之外 --> 顺丰 -- 配送方案最长接单时间 --> 取消创建新运单推送自配送 --空闲骑手--> SECOND[直接分配]--> 结束 取消创建新运单推送自配送 -- 可以并单 --> 直接并入批次--> 结束 取消创建新运单推送自配送 -- 不可以并单 --> 创建新的批次 --> 结束 这张图确实丑了点,嗯,我现在还不熟练,但是这个流程称得上很清晰了","link":"/2020/11/20/typora%E4%BD%BF%E7%94%A8/"},{"title":"双数据源实现方式二-区分包扫描方式","text":"[toc] 包扫描方式 上文写到的第一种方法aop没有切到父类方法,解决方法也有多种;可以百度搜下; 这篇文章的方案是: 不同的包对应不同的数据源 ; 这种访问的重点就是配置.配置只要对了; 就很简单 step1:配置datasource/mapperscanner/sqlsessionfactory注意将原先的@MapperScan注解干掉,下面会自定义 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Bean(&quot;sqlServerDS&quot;)@Primary@ConfigurationProperties(prefix = &quot;sqlserver.datasource&quot;)public DataSource sqlServerDS() { return DataSourceBuilder.create().type(HikariDataSource.class).build();}@Bean(&quot;mysqlDS&quot;)@ConfigurationProperties(prefix = &quot;mysql.datasource&quot;)public DataSource mysqlDS() { return DataSourceBuilder.create().type(HikariDataSource.class).build();}@Primary@Beanpublic SqlSessionFactory sqlServerSqlSessionFactory(@Qualifier(&quot;sqlServerDS&quot;) DataSource dataSource) throws Exception { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(dataSource); return factoryBean.getObject();}@Beanpublic SqlSessionFactory mysqlSqlSessionFactory(@Qualifier(&quot;mysqlDS&quot;) DataSource dataSource) throws Exception { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(dataSource); return factoryBean.getObject();}@Beanpublic MapperScannerConfigurer sqlServerMapperScanner() { MapperScannerConfigurer sqlServerMapperScanner = new MapperScannerConfigurer(); sqlServerMapperScanner.setSqlSessionFactoryBeanName(&quot;sqlServerSqlSessionFactory&quot;); sqlServerMapperScanner.setBasePackage(&quot;com.freemud.order.dao.sqlserver&quot;); Properties properties = new Properties(); properties.setProperty(&quot;mappers&quot;, Mapper.class.getName()); properties.setProperty(&quot;notEmpty&quot;, &quot;false&quot;); properties.setProperty(&quot;IDENTITY&quot;, &quot;SqlServer&quot;); sqlServerMapperScanner.setProperties(properties); return sqlServerMapperScanner;}@Beanpublic MapperScannerConfigurer mysqlMapperScanner() { MapperScannerConfigurer sqlServerMapperScanner = new MapperScannerConfigurer(); sqlServerMapperScanner.setSqlSessionFactoryBeanName(&quot;mysqlSqlSessionFactory&quot;); sqlServerMapperScanner.setBasePackage(&quot;com.freemud.order.dao.mysql&quot;); Properties properties = new Properties(); properties.setProperty(&quot;mappers&quot;, Mapper.class.getName()); properties.setProperty(&quot;notEmpty&quot;, &quot;false&quot;); properties.setProperty(&quot;IDENTITY&quot;, &quot;MySQL&quot;); sqlServerMapperScanner.setProperties(properties); return sqlServerMapperScanner;} step2: 整理自己的代码分层比如将原先的dao 分为dao.mysql; 和dao.sqlserver; 不同的数据源对应不同的包这样子 step3: 代码使用本次使用的场景是数据库逐步迁移; 因此做了黑白名单,默认sqlserver; 上了名单走mysql 123456789public BaseResponse queryOrderListByTime(OrderVo vo) { List&lt;? extends OrderDto&gt; orderDtos ; if (vo.getDsTypeEnum() == DSTypeEnum.SQLSERVER) { orderDtos = orderDao.selectByOrderVo(vo); }else{ orderDtos = mySqlOrderDao.selectByOrderVo(vo); } return ResponseUtil.success(orderDtos); } 注意事项 不同的datasource的配置略有不同,比如durid的是url; 而HikariDataSource是jdbc-url 项目中原先的@MapperScan要干掉; MapperScannerConfigurer这个要注意; 因为代码有一定演示意义在内,实际中如果你继承的不是Mapper;而是自定义的需要加到这里面; 多个就用逗号隔开","link":"/2020/11/20/%E5%8F%8C%E6%95%B0%E6%8D%AE%E6%BA%90%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E4%BA%8C-%E5%8C%BA%E5%88%86%E5%8C%85%E6%89%AB%E6%8F%8F%E6%96%B9%E5%BC%8F/"},{"title":"双数据源实现方式一-注解方式","text":"注解+aop 先把个人的结论写前面 通过aop + 注解的形式在切面切换数据源实现 优势: 对本身的代码分层没有任何变化.即两个数据源对应的entity/repository不变 劣势: aop切父类方法会失效;即:如果使用通用mapper则会导致父类方法没切到 通过不同数据源扫描不同的包实现 优势: 只关心实体类对应包即可,不需要额外增加注解 劣势:有一定的侵入; 比如原本dao在repository包下,现在需要再建一个;比如原先的迁移到dao.primary包下; 第二数据源放在dao.second包下 第一种方式: aop+注解流程效果 : 调用repository层方法前;通过切面切换数据源; 直接撸代码 step1 增加注解:因为一个repository类不应该同时对应两个数据库; 应该注解指定定义类使用即可 12345678@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value = {ElementType.TYPE})public @interface DataSourceType { DBTypeEnum value() default DBTypeEnum.PRIMARY;} 同时定义下两种不同数据源的枚举 12345678910@Getterpublic enum DBTypeEnum { PRIMARY(&quot;primaryDb&quot;), LOG(&quot;logDb&quot;),; private String dbName; DBTypeEnum(String dbName) { this.dbName = dbName; }} step2 动态数据源123456789spring.datasource.druid.url=jdbc:mysql://127.0.0.1:3306/sharding_0?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=UTCspring.datasource.druid.username=rootspring.datasource.druid.password=rootspring.datasource.druid.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.log.url=jdbc:mysql://127.0.0.1:3306/sharding_1?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;useSSL=false&amp;serverTimezone=UTCspring.datasource.log.username=rootspring.datasource.log.password=rootspring.datasource.log.driver-class-name=com.mysql.cj.jdbc.Driver 1234567891011121314151617181920212223242526272829303132333435@Bean@Primary@ConfigurationProperties(&quot;spring.datasource.druid&quot;)public DataSource primaryDb() { return DruidDataSourceBuilder.create().build();}@Bean@ConfigurationProperties(&quot;spring.datasource.log&quot;)public DataSource logDb() { return DruidDataSourceBuilder.create().build();}@Beanpublic DynamicDataSource dynamicDataSource(@Qualifier(&quot;primaryDb&quot;) DataSource primaryDb, @Qualifier(&quot;logDb&quot;) DataSource logDb) { Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(DBTypeEnum.PRIMARY, primaryDb); targetDataSources.put(DBTypeEnum.LOG, logDb); return new DynamicDataSource(primaryDb, targetDataSources);}/** * 低版本中SqlSessionFactory会自动注入; 高版本取消了sqlsessionfactory的自动注入; 需要自己手动注入 * @param dynamicDataSource * @return * @throws Exception */@Beanpublic SqlSessionFactory sqlSessionFactory(DynamicDataSource dynamicDataSource) throws Exception { final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(dynamicDataSource); return sessionFactory.getObject();} 123456789101112131415161718192021public class DynamicDataSource extends AbstractRoutingDataSource { private static final ThreadLocal&lt;DBTypeEnum&gt; DB_HOLDER = new ThreadLocal&lt;&gt;(); public DynamicDataSource(DataSource defaultTargetDataSource, Map&lt;Object, Object&gt; targetDataSource) { super.setDefaultTargetDataSource(defaultTargetDataSource); super.setTargetDataSources(targetDataSource); super.afterPropertiesSet(); } @Override protected Object determineCurrentLookupKey() { return DB_HOLDER.get(); } public static void setDBType(DBTypeEnum dbType) { DB_HOLDER.set(dbType); } public static DBTypeEnum getDBType() { return DB_HOLDER.get(); } public static void clearDBType() { DB_HOLDER.remove(); }} step3 定义aop1234567891011121314@Before(value = &quot;execution(* com.daily.multipledatasource01.repository..*.*(..))&quot;) public void doBefore(JoinPoint joinPoint) { Class targetClass = joinPoint.getSignature().getDeclaringType(); DataSourceType annotation = AnnotationUtils.findAnnotation(targetClass, DataSourceType.class); if (annotation != null) { DynamicDataSource.setDBType(annotation.value()); } } @After(value = &quot;execution(* com.daily.multipledatasource01.repository..*.*(..))&quot;) public void doAfter(JoinPoint joinPoint) { DynamicDataSource.clearDBType(); } step4 代码使用父类方法的接口没有切到,所以暂时先写一个新的方法跑通流程 123456@DataSourceType(DBTypeEnum.LOG)public interface OrderLogRepository extends Mapper&lt;OrderLog&gt; { default int save(OrderLog orderLog) { return insert(orderLog); }}","link":"/2020/11/20/%E5%8F%8C%E6%95%B0%E6%8D%AE%E6%BA%90%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%E4%B8%80-%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F/"},{"title":"延时队列的不同实现形式","text":"将死信队列升级为延时队列 客户的数据不推送到我们服务中,创建配送单的方式是手动拉他们的数据创建配送单;门店有一个制作时间,因此会设置一个延迟推送时间(可配置); 如下单6分钟后该创建该运单的配送单 历史做法 创建一个定时任务; 1分钟拉取一次数据; 将符合条件的数据设置超时时间放到一个无消费者的队列中 队列延时时间到了之后, 丢入死信队列中 死信队列的消费者会先查该运单是否创建过(因为6分钟可能被拉取到6次); 如果没有创建过则创建一条运单 改造原因(主要还是第二条) 1.上述提到的6分钟可配置; 由于是一个定制化商户;这个商户曾连续修改这个值;已经有了延迟1,3,5,6,7,8,9,10,15,30,60这么多延时的死信队列了; 还提出有新的延迟时间 2.逻辑已经上线N个月了; 我刚接手一个月说这个时间不准确; 延迟6分钟; 但是他们看到的是超过了6分钟多了几秒; 感觉在欺负我一样 3.代码太乱了; 因为每一个延迟时间就创建两个队列; 在声明的类中代码太长;接手就发现7分钟的延迟对了用的是五分钟的配置.查问题不好查 改造方式1(客户需要配合) 要求: 1.mq版本升级到3.6以上 (项目已支持)2.安装动态延迟队列插件: rabbitmq_delayed_message_exchange 实现 创建队列1234567891011121314151617 @Bean CustomExchange multipleDelayExchange(){ Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(&quot;x-delayed-type&quot;, &quot;direct&quot;); return new CustomExchange(DELAY_EXCHANGE, &quot;x-delayed-message&quot;, true, false, args); } @Bean Queue multipleDelayQueue() { return new Queue(DELAY_QUEUE, true); } @Bean Binding multipleDelayBinding() { return BindingBuilder.bind(multipleDelayQueue()) .to(multipleDelayExchange()) .with(DELAY_ROUTING) .noargs(); } 消费者12345 @RabbitListener(queues = MultiplexDlConfig.DELAY_QUEUE) public void consumer(String msg, Message message) { log.info(&quot;当前时间: {} ,message : {} &quot;, LocalDateTime.now(), message); } 发送端123456789101112 @PostMapping(&quot;/send&quot;) public ResponseEntity&lt;String&gt; multipleDlSendMsg(@RequestBody MultipleDlRequest multipleDlRequest) { rabbitTemplate.convertAndSend(MultiplexDlConfig.DELAY_EXCHANGE, MultiplexDlConfig.DELAY_ROUTING, multipleDlRequest.getMessage(), msg -&gt; { log.info(&quot;当前时间: {} ,msg : {} &quot;, LocalDateTime.now(), msg); Integer delayTime = multipleDlRequest.getDlTime() * 1000; msg.getMessageProperties().setHeader(&quot;x-delay&quot;, delayTime); return msg; }); return ResponseEntity.ok(&quot;ok&quot;); } 方式2(客户不配合) 客户要是配合的话也不会出现定时拉取他们数据这种情况, 所以上面的是主要方案; 这个是备选方案 参考地址:有赞延迟队列设计demo已经写过; 对于wait/notify因为需求又来了一批;回头尝试下 总结下延迟队列的实现形式 不考虑延时的实时性; 使用定时任务+死信队列 使用mq延时队列 redis的zset来实现延时队列","link":"/2020/09/27/%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/"},{"title":"hexo","text":"hexo学习 参考博客如下: hexo从零开始到搭建完整 hexo史上最全搭建教程 技术小白搭建个人博客 github+hexo 写博客常用命令 hexo Docs 博客本地启动: hexo s = hexo server 本地创建一个新的页面: hexo new [title] 写完之后生成静态文件: hexo g = hexo generate 提交到远程git上: hexo d = hero deploy 主题修改根据上面的搭建博客后; 因为太丑,因此网上查下哪款主题比较好看 作为一个审美并不强的人,在一个非官方的统计中,icarus排名第一我并不是一个特别纠结的人; 在都不认识的情况下,我选择第一名,即时不是最佳,也一定不会差, 主题并不算复杂;但是有一篇文章写得挺好,可能在版本上有点久(新版本使用的react);但是借鉴意义我感觉特别好 Hexo+icarus主题配置","link":"/2020/09/25/hexo/"},{"title":"hexo多台电脑","text":"多台电脑的博客同步 一般来说,我们写博客不会只在一台电脑上使用,比如公司一台电脑家里一台电脑 在比如我,我在家是用台式电脑的, 这样就会有三台电脑,我可以控制在一台电脑上使用,但是明显能够在三台电脑上都能够写文章是最佳的,因此需要三台电脑进行同步 方案一这种方案最简单,也最差劲 将自己本地的文件进行拷贝;然后再第二台电脑上安装好hexo和node.js环境后,你就可以再第二台电脑上写自己的博文 但是这样子你之前的文章你需要一直的进行拷贝;明显不符合我们的需求,这种情况只适用于有一台电脑,刚好要换一台电脑的情况(但是如果电脑崩溃了…那就彻底没了) 方案二将自己的东西放到互联网上,这样子可以比较好的防止自己的东西丢失; 这个我是将自己的文件放到了git上; github支持创建私有仓库,但是我hexo上没有隐私的账号之类的东西,因此我选择与博客放在一个repository进行管理,步骤如下: 创建一个分支,比如hexo 本地clone 切换分支到hexo中 git checkout hexo 当我们执行hexo g后,hexo是将文件放在了public文件夹下,而我们执行hexo d也是将public文件下的东西上传到gitub上去,所以我们现在需要将上一级也就是public文件这一级的文件上传到hexo分支中来; 因此先将所有文件进行删除 如果你的文件夹是展示隐藏文件的话,不要删除掉.git文件 将hexo的文件夹拷贝到当前目录,然后上传到github上 git add . git commit -m ‘hexo init’ git push 如果你选择了主题,当你执行git add .时,并没有将所有文件添加到git进行管理,因为这时候你的主题文件夹下也有一个.git文件.这时候我们需要将主题不交于git管理,比如我使用的theme是icarus;操作如下 cd theme/icarus git status - 查看下当前的分支;我这边是默认的origin git remote rm origin 这时候与远程将不再有关系,再删除文件下的.git文件(可能直接删除也可以,不过我是先解除了远程的绑定) 如果没有找到.git;就在查看中展示隐藏文件(.git默认是隐藏文件) 重新执行上面的git add .;然后进行提交 这时候我们的hexo相关的文件都在git上进行了托管;当我们切换电脑/或者在另一台电脑上使用时.只需要在父目录下git pull一下就可以同步我们的文件 最后:如果不希望自己的源文件被别人看到; 可以用相同的办法上传到一个private的repository中","link":"/2020/11/28/hexo%E5%A4%9A%E5%8F%B0%E7%94%B5%E8%84%91/"},{"title":"Spring Boot 与 Spring Cloud版本不一致(一)","text":"Spring Boot 与 Spring Cloud版本不一致时引入Prometheus进行服务监控时服务启动报错追踪 Spring Boot 和Spring Cloud 版本关系对应表: https://spring.io/projects/spring-cloud 项目报错 今天测试告知服务启动失败,服务pull代码后正常启动 执行maven clean重新build后启动报错,报错日志如下: 12345678910111213141516171819202122232425262728293031***************************APPLICATION FAILED TO START***************************Description:An attempt was made to call a method that does not exist. The attempt was made from the following location: org.springframework.cloud.client.discovery.health.DiscoveryCompositeHealthIndicator.&lt;init&gt;(DiscoveryCompositeHealthIndicator.java:42)The following method did not exist: org.springframework.boot.actuate.health.CompositeHealthIndicator.&lt;init&gt;(Lorg/springframework/boot/actuate/health/HealthAggregator;)VThe method's class, org.springframework.boot.actuate.health.CompositeHealthIndicator, is available from the following locations: jar:file:/D:/framework/develop/idea/repository/org/springframework/boot/spring-boot-actuator/2.2.2.RELEASE/spring-boot-actuator-2.2.2.RELEASE.jar!/org/springframework/boot/actuate/health/CompositeHealthIndicator.classIt was loaded from the following location: file:/D:/framework/develop/idea/repository/org/springframework/boot/spring-boot-actuator/2.2.2.RELEASE/spring-boot-actuator-2.2.2.RELEASE.jarAction:Correct the classpath of your application so that it contains a single, compatible version of org.springframework.boot.actuate.health.CompositeHealthIndicatorDisconnected from the target VM, address: '127.0.0.1:0', transport: 'socket'Process finished with exit code 1 代码/错误日志 跟踪根据git log的commit查到有人在服务中接入Prometheus进行服务监控 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; 和报错已经特别吻合了; 当时脑海里立马想到的就是是不是springcloud和springboot的版本不一致,这里先把项目原先的版本列出 12Spring Boot - 2.2.2.RELEASESpring Cloud - Greenwich.SR3 错误日志提示的比较明显,直接点击到类中 DiscoveryCompositeHealthIndicator对应的jar包spring-cloud-common:2.1.3.RELEASE注:down下来直接是报错的 1234567891011@Autowiredpublic DiscoveryCompositeHealthIndicator(HealthAggregator healthAggregator, List&lt;DiscoveryHealthIndicator&gt; indicators) { -- 这里在报错 super(healthAggregator); for (DiscoveryHealthIndicator indicator : indicators) { Holder holder = new Holder(indicator); addHealthIndicator(indicator.getName(), holder); this.healthIndicators.add(holder); }} 打开父类方法 (spring-boot-actuator-2.2.2.RELEASE) : 12345678910111213/** * {@link HealthIndicator} that returns health indications from all registered delegates. * * @author Tyler J. Frederick * @author Phillip Webb * @author Christian Dupuis * @since 1.1.0 * @deprecated since 2.2.0 in favor of a {@link CompositeHealthContributor} */@Deprecatedpublic class CompositeHealthIndicator implements HealthIndicator { ...} 明显被启用了; 对应的构造器也不存在了 升级spring Cloud版本按照官网版本关系,在项目的pom文件中(因为父pom是设计其他服务伙伴使用; 因此抛出改问题后先修改自己的pom文件) 1234567891011 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR8&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; – END AND NOTE Spring Cloud 和Spring Boot版本不一致的问题时有发生,有时候可能正常运行,但是一旦接入其他jar包就会由此产生问题,因此Spring Boot和Spring Cloud的版本升级尽量保持同步","link":"/2020/12/13/springboot%E7%89%88%E6%9C%AC%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98(%E4%B8%80)/"},{"title":"当接手一个新的项目时需要优先注意的点","text":"接手的项目可能是一个好项目; 但一般来说烂项目的多一些,接手后需要检查一些事情,防止被坑 基础检查数据库 检查核心流程的sql是否走索引.特别是更新语句,不走索引会锁全表 影响:随着表数据量多,当出现并发请求时会造成堵塞 生产的数据库必须要一个只读账号让所有开发/技术支持使用 服务 是否存在单节点的服务,升级多个服务,注意是否有定时任务,多台是否有影响 要与项目或运营及时沟通,如果客户有很大活动可能会造成请求骤升;考虑是否需要扩容 代码 对代码的线程池必须检查下,特别是异步走默认配置的,会有一个Integer.MAX_VALUE长度的队列,并且服务重启队列中的消息会直接丢失并且堵塞不易被监控到 mq消费者是否有try-catch;防止消息被堵住 重试/递归场景是否会因为数据问题出现无限循环的情况 查询语句根据场景加时间区间,防止数据量提升后sql性能骤降 使用分布式锁是否有被正常释放 日志和监控 针对日志中所有error日志进行跟踪排查,需要修复的进行修复，每一次发版后对error日志必须严格跟踪,次日再次跟踪 要做好链路追踪,包括内部的消费服务,对于重要日志要进行补充提升处理问题的效率 对监控到慢sql要进行追踪 对堵塞的queue要立刻跟踪 监控服务器/db/redis/mq 的 内存/cpu进行监控 项目开发需求 影响使用的bug要优先解决; 如果影响需求开发,项目和产品一般来说不管bug!!!, 和项目扯皮,互相理解下,让他们的需求延后; 非紧急bug在日常迭代中适当安排进行处理","link":"/2020/12/05/%E6%8E%A5%E6%89%8B%E4%B8%80%E4%B8%AA%E5%B7%AE%E5%8A%B2%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%90%8E%E6%84%9F%E6%83%B3/"},{"title":"logback的使用","text":"logback日志打印; 以及控制日志大小/保留天数的控制 将error日志和普通打印打印分开 在appender中增加过滤器 123&lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;WARN&lt;/level&gt;&lt;/filter&gt; 设置日志文件大小和时效 TimeBasedRollingPolicy 升级为 SizeAndTimeBasedRollingPolicy fileNamePattern需要增加.%i用于文件分割 maxHistory为最多保留天数 totalSizeCap为日志容量;防止日志占用服务器太多资源 区分不同的环境 如果使用标签则代表所有环境统一,也可以根据不同的环境设置不同的打印方式如: 1234567&lt;springProfile name = &quot;dev&quot;&gt; &lt;root level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console-local&quot; /&gt; &lt;appender-ref ref=&quot;ALL&quot; /&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt; &lt;/root&gt; &lt;/springProfile&gt; 注意自定义后不可在使用标签会造成日志会打印两份 链路追踪 @see org.slf4j.MDC MDC在logback中用%X可以获取；假设有代码： 1MDC.put(&quot;tid&quot;, UUIDUtils.getUUID()); 则可以在logback中用%X{tid} 获取到该值 ， 这样便于链路追踪的日志打印 logback的一个demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;contextName&gt;log&lt;/contextName&gt; &lt;property name=&quot;projectName&quot; value=&quot;logTest&quot;/&gt; &lt;property name=&quot;logPath&quot; value=&quot;/data/logs&quot; /&gt; &lt;property name=&quot;defaultEncoderPattern&quot; value=&quot;%d{HH:mm:ss.SSS} %contextName [%X{tid}] %-5level %logger{36} - %msg%n&quot; /&gt; &lt;!--输出到控制台--&gt; &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;${defaultEncoderPattern}&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到控制台--&gt; &lt;appender name=&quot;console-local&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %boldYellow(%X{ThreadID}) %highlight(%-5level) %boldGreen(%logger{36}.%method:%line) - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 输出全部日志到文件中 --&gt; &lt;appender name=&quot;ALL&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;${logPath}/${projectName}/${projectName}.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;${logPath}/${projectName}/${projectName}-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;totalSizeCap&gt;8GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;${defaultEncoderPattern}&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 错误日志：用于将错误日志输出到独立文件 --&gt; &lt;appender name=&quot;ERROR_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;${logPath}/${projectName}/error-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;totalSizeCap&gt;8GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;${defaultEncoderPattern}&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;root level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console&quot; /&gt; &lt;appender-ref ref=&quot;ALL&quot; /&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt; &lt;/root&gt; &lt;!-- &lt;springProfile name = &quot;dev&quot;&gt; &lt;root level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;console-local&quot; /&gt; &lt;appender-ref ref=&quot;ALL&quot; /&gt; &lt;appender-ref ref=&quot;ERROR_FILE&quot; /&gt; &lt;/root&gt; &lt;/springProfile&gt;--&gt;&lt;/configuration&gt;","link":"/2021/01/23/logback%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"utools牛皮","text":"名字起得很合适: 生产力工具集,很好用","link":"/2021/02/04/utools%E7%89%9B%E7%9A%AE/"},{"title":"springBoot创建bean的三层缓存源码跟踪","text":"Spring是如何解决循环依赖呢?这是一个开发中习惯,但是spring是如何处理呢? 跟踪目标只跟踪下常见的singleton对象的出现相互依赖时的流程 项目 单纯的springboot项目 springboot 版本 模块只引用了spring-boot-starter-web 1id 'org.springframework.boot' version '2.4.1' 123implementation 'org.springframework.boot:spring-boot-starter-web' implementation 'org.projectlombok:lombok' 基础的三个类 12345678910111213@Componentpublic class B { @Autowired private A a;}@Componentpublic class A { @Autowired private B b;} debug模式断点的入口 refreshContext –&gt;refresh–&gt;finishBeanFactoryInitialization 123//实例化剩下的所有非懒加载的单例对象 -- 有一些单例对象在容器准备阶段已经实例化,所以这里是加载剩余的 // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); finishBeanFactoryInitialization–&gt;preInstantiateSingletons 123 //正式开始实例化// Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons(); 具体代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Overridepublic void preInstantiateSingletons() throws BeansException { if (logger.isTraceEnabled()) { logger.trace(&quot;Pre-instantiating singletons in &quot; + this); } // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); //本文章跟踪的核心代码: load阶段,所有bean的名称保存在beanNames中,这里开始初始化 // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) { //debug断点: beanName.equalsIgnoreCase(&quot;a&quot;)||beanName.equalsIgnoreCase(&quot;b&quot;) RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { if (isFactoryBean(beanName)) { Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) { FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) { isEagerInit = AccessController.doPrivileged( (PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); } else { isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); } // if (isEagerInit) { getBean(beanName); } } } else { //普通bean,因此所有断点的入口将由这里开始 getBean(beanName); } } } // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) { Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) { StartupStep smartInitialize = this.getApplicationStartup().start(&quot;spring.beans.smart-initialize&quot;) .tag(&quot;beanName&quot;, beanName); SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; { smartSingleton.afterSingletonsInstantiated(); return null; }, getAccessControlContext()); } else { smartSingleton.afterSingletonsInstantiated(); } smartInitialize.end(); } }} A对象实例化实例化前: singletonObjects(最外层缓存): 59个; 不包含a,b两个对象 earlySingletonObjects (中间缓存)为空 singletonFactories(内部缓存)为空 实例化开始标记为开始创建外层缓存不包含该对象,因此第一步标记为创建中 123if (!typeCheckOnly) { markBeanAsCreated(beanName);} 12345678910111213protected void markBeanAsCreated(String beanName) { if (!this.alreadyCreated.contains(beanName)) { synchronized (this.mergedBeanDefinitions) { if (!this.alreadyCreated.contains(beanName)) { // Let the bean definition get re-merged now that we're actually creating // the bean... just in case some of its metadata changed in the meantime. //注释已经提到,将beandefinition的stale改为true ,后续获取bean的定义则需要重新merge,防止定义发生改变 clearMergedBeanDefinition(beanName); this.alreadyCreated.add(beanName); } } }} alreadyCreated为已经创建完成的bean的表示, 一旦一个线程开始创建,则其他线程需要判断已创建则不可再创建 tag开始12StartupStep beanCreation = this.applicationStartup.start(&quot;spring.beans.instantiate&quot;) .tag(&quot;beanName&quot;, name); 开始创建12345678910111213141516// Create bean instance.if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, () -&gt; { try { return createBean(beanName, mbd, args); } catch (BeansException ex) { // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);} getSingleton这个方法应该为完整的bean的创建流程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) { Assert.notNull(beanName, &quot;Bean name must not be null&quot;); synchronized (this.singletonObjects) { Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) { if (this.singletonsCurrentlyInDestruction) { throw new BeanCreationNotAllowedException(beanName, &quot;Singleton bean creation not allowed while singletons of this factory are in destruction &quot; + &quot;(Do not request a bean from a BeanFactory in a destroy method implementation!)&quot;); } if (logger.isDebugEnabled()) { logger.debug(&quot;Creating shared instance of singleton bean '&quot; + beanName + &quot;'&quot;); } //流程一 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) { this.suppressedExceptions = new LinkedHashSet&lt;&gt;(); } try { //流程二 singletonObject = singletonFactory.getObject(); newSingleton = true; } catch (IllegalStateException ex) { // Has the singleton object implicitly appeared in the meantime -&gt; // if yes, proceed with it since the exception indicates that state. singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) { throw ex; } } catch (BeanCreationException ex) { if (recordSuppressedExceptions) { for (Exception suppressedException : this.suppressedExceptions) { ex.addRelatedCause(suppressedException); } } throw ex; } finally { if (recordSuppressedExceptions) { this.suppressedExceptions = null; } //流程三 afterSingletonCreation(beanName); } if (newSingleton) { //流程四 addSingleton(beanName, singletonObject); } } return singletonObject; }} 这里流程一和流程三是对应关系, 将singletonsCurrentlyInCreation标记进行处理 流程三和流程四是结束时的操作,下面是流程二的操作 12345protected void beforeSingletonCreation(String beanName) { if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.add(beanName)) { throw new BeanCurrentlyInCreationException(beanName); }} 流程二见下面createBean跟踪 createBean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { if (logger.isTraceEnabled()) { logger.trace(&quot;Creating instance of bean '&quot; + beanName + &quot;'&quot;); } RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) { mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); } // Prepare method overrides. try { mbdToUse.prepareMethodOverrides(); } catch (BeanDefinitionValidationException ex) { throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, &quot;Validation of method overrides failed&quot;, ex); } try { // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) { return bean; } } catch (Throwable ex) { throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, &quot;BeanPostProcessor before instantiation of bean failed&quot;, ex); } try { //这个方法将创建出一个bean的实例 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isTraceEnabled()) { logger.trace(&quot;Finished creating instance of bean '&quot; + beanName + &quot;'&quot;); } return beanInstance; } catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) { // A previously detected exception with proper bean creation context already, // or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry. throw ex; } catch (Throwable ex) { throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, &quot;Unexpected exception during bean creation&quot;, ex); }} doCreateBean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) { instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); } if (instanceWrapper == null) { //这里会创建好bean的包装类 instanceWrapper = createBeanInstance(beanName, mbd, args); } //这个bean就是未来的a;只不过现在是个空的,只有一个内存地址 Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) { mbd.resolvedTargetType = beanType; } // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) { if (!mbd.postProcessed) { try { applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); } catch (Throwable ex) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Post-processing of merged bean definition failed&quot;, ex); } mbd.postProcessed = true; } } // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. //主动缓存单例，以便能够解析循环引用 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) { if (logger.isTraceEnabled()) { logger.trace(&quot;Eagerly caching bean '&quot; + beanName + &quot;' to allow for resolving potential circular references&quot;); } //这里将bean将放入最内部的缓存中: singletonFactories缓存中; addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); } // Initialize the bean instance. Object exposedObject = bean; try { //对象的填充 --&gt; A 中注入 B 将由这里处理 populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); } catch (Throwable ex) { if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) { throw (BeanCreationException) ex; } else { throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex); } } if (earlySingletonExposure) { Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) { if (exposedObject == bean) { exposedObject = earlySingletonReference; } else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) { String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) { if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) { actualDependentBeans.add(dependentBean); } } if (!actualDependentBeans.isEmpty()) { throw new BeanCurrentlyInCreationException(beanName, &quot;Bean with name '&quot; + beanName + &quot;' has been injected into other beans [&quot; + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + &quot;] in its raw version as part of a circular reference, but has eventually been &quot; + &quot;wrapped. This means that said other beans do not use the final version of the &quot; + &quot;bean. This is often the result of over-eager type matching - consider using &quot; + &quot;'getBeanNamesForType' with the 'allowEagerInit' flag turned off, for example.&quot;); } } } } // Register bean as disposable. try { registerDisposableBeanIfNecessary(beanName, bean, mbd); } catch (BeanDefinitionValidationException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex); } return exposedObject;} getEarlyBeanReference放入三级缓存一个bean的工厂类,而getEarlyBeanReference则时这个工厂的匿名内部类 123456789protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) { Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { for (SmartInstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().smartInstantiationAware) { exposedObject = bp.getEarlyBeanReference(exposedObject, beanName); } } return exposedObject;} populateBean12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) { if (bw == null) { if (mbd.hasPropertyValues()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;); } else { // Skip property population phase for null instance. return; } } // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) { if (!bp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) { return; } } } PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); int resolvedAutowireMode = mbd.getResolvedAutowireMode(); if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) { MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (resolvedAutowireMode == AUTOWIRE_BY_NAME) { autowireByName(beanName, mbd, bw, newPvs); } // Add property values based on autowire by type if applicable. if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) { autowireByType(beanName, mbd, bw, newPvs); } pvs = newPvs; } boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) { if (pvs == null) { pvs = mbd.getPropertyValues(); } //instantiationAware中有三个BeanPostProcessor,其中AutowiredAnnotationBeanPostProcessor会对b进行注入 for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) { PropertyValues pvsToUse = bp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) { if (filteredPds == null) { filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); } pvsToUse = bp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) { return; } } pvs = pvsToUse; } } if (needsDepCheck) { if (filteredPds == null) { filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); } checkDependencies(beanName, mbd, filteredPds, pvs); } if (pvs != null) { applyPropertyValues(beanName, mbd, bw, pvs); }} AutowiredAnnotationBeanPostProcessor1234567891011121314@Overridepublic PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) { InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); try { metadata.inject(bean, beanName, pvs); } catch (BeanCreationException ex) { throw ex; } catch (Throwable ex) { throw new BeanCreationException(beanName, &quot;Injection of autowired dependencies failed&quot;, ex); } return pvs;} 实施注入: 12345678910public void inject(Object target, @Nullable String beanName, @Nullable PropertyValues pvs) throws Throwable { Collection&lt;InjectedElement&gt; checkedElements = this.checkedElements; Collection&lt;InjectedElement&gt; elementsToIterate = (checkedElements != null ? checkedElements : this.injectedElements); if (!elementsToIterate.isEmpty()) { for (InjectedElement element : elementsToIterate) { element.inject(target, beanName, pvs); } }} 注入的流程resolveDependency 简述 findAutowireCandidates - 获取需要注入的对象 resolveCandidate –&gt; 从当前的容器(DefaultListableBeanFactory)中查找B B在容器中查找时执行和A一样的流程; 但是此时A属于在创建中,但是在第三层缓存中;B可以获取到A;因此B可以创建成功 创建完成@see getSingleton中流程二和流程四 12345protected void afterSingletonCreation(String beanName) { if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.remove(beanName)) { throw new IllegalStateException(&quot;Singleton '&quot; + beanName + &quot;' isn't currently in creation&quot;); }} 流程四则是bean创建完成后对缓存的操作,这里是将中间层和最内部的缓存清掉当前bean,并放入外层缓存中 12345678protected void addSingleton(String beanName, Object singletonObject) { synchronized (this.singletonObjects) { this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); }} tag结束beanCreation.end(); 结束其他目前的代码中并没有真正的使用到三层缓存(虽然B找到A后会将A从底层移到中间层中); 这点后续再说","link":"/2021/02/22/spring%E5%88%9B%E5%BB%BAbean%E7%9A%84%E4%B8%89%E5%B1%82%E7%BC%93%E5%AD%98%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/"},{"title":"代码技巧_枚举","text":"根据一个值来反向查找一个枚举在代码中很常见,这个反查的代码存在大量的重复如何优化掉呢? 介绍枚举在我们日常代码中是必不可少的,尤其是系统中的状态/错误嘛/操作类型等,通常我们是使用枚举来进行定义的; 在联调中;外部通常传递的是一个具体的数字;代码流转中通常则使用枚举进行流转,所有这种方法getEnumByCode通常会在枚举中定义, 但是这个方法在所有枚举中都是一样的 示例123456789101112131415161718192021222324252627@Getterpublic enum StatusEnum{ SLEEP(0,&quot;睡觉&quot;), EAT(1, &quot;吃&quot;) ; private Integer code; private String desc; StatusEnum(Integer code, String desc) { this.code = code; this.desc = desc; } public StatusEnum getStatusEnumByCode(Integer code) { if (code == null) { return null; } for (StatusEnum value : values()) { if (ObjectUtils.nullSafeEquals(value.getCode(), code)) { return value; } } return null; }} 优化通过枚举实现接口,再通过反射来对所有枚举统一处理 talk is cheap 接口123public interface CodeEnum { Integer getCode();} 工具类12345678910111213141516public interface EnumUtils { static &lt;T extends CodeEnum&gt; T getByCode(Integer code, Class&lt;T&gt; t) { if(code == null){ return null; } T[] enumConstants = t.getEnumConstants(); for (T codeEnum : enumConstants) { if (ObjectUtils.nullSafeEquals(code, codeEnum.getCode())) { return codeEnum; } } return null; }} 所有枚举实现该接口123456789101112131415@Getterpublic enum StatusEnum implements CodeEnum { SLEEP(0,&quot;睡觉&quot;), EAT(1, &quot;吃&quot;) ; private Integer code; private String desc; StatusEnum(Integer code, String desc) { this.code = code; this.desc = desc; }} 测试代码12345public static void main(String[] args) { Integer code = 1; StatusEnum statusEnum = EnumUtils.getByCode(1, StatusEnum.class); System.out.println(&quot;statusEnum = &quot; + statusEnum); } 控制台输出1statusEnum = EAT","link":"/2021/03/16/%E4%BB%A3%E7%A0%81%E6%8A%80%E5%B7%A7-%E6%9E%9A%E4%B8%BE/"},{"title":"代码技巧-分批查询","text":"数据库批量插入如何优化的分批操作 预期目的批量操作当出现数据太多时优雅的解决问题,减少代码的重复工作 下面以一个批量插入的代码进行示例 优化前批量操作demo方法123public static void insertList(List&lt;String&gt; ids) { System.out.println(&quot;ids = &quot; + ids);} 调用处1234List&lt;List&lt;String&gt;&gt; partition = Lists.partition(ids, 100); for (List&lt;String&gt; subIds : partition) { insertList(subIds);} 优化后封装的模板工具类1234567static &lt;T&gt; void partitionExecute(List&lt;T&gt; list, Integer pageSize, Consumer&lt;List&lt;T&gt;&gt; consumer) { pageSize = Optional.ofNullable(pageSize).orElse(100); List&lt;List&lt;T&gt;&gt; partition = Lists.partition(list, pageSize); for (List&lt;T&gt; tList : partition) { consumer.accept(tList); } } 新老代码对比12345678910111213141516public static void main(String[] args) { List&lt;String&gt; ids = Lists.newArrayList(&quot;1&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;); oldStyle(ids); newStyle(ids);}public static void oldStyle(List&lt;String&gt; ids) { List&lt;List&lt;String&gt;&gt; partition = Lists.partition(ids, 100); for (List&lt;String&gt; subIds : partition) { insertList(subIds); }}public static void newStyle(List&lt;String&gt; ids) { ListPagingUtils.partitionExecute(ids, 3, list -&gt; insertList(list));} 优化说明上述demo比较简单,实际中不仅仅是批量插入, 也可以是其他的批量操作,如一个简单根据id进行查询的封装 12345678910111213static &lt;T, R&gt; List execute(List&lt;T&gt; list, Integer pageSize, Function&lt;List&lt;T&gt;,List&lt;R&gt;&gt; function) { List&lt;R&gt; result = new ArrayList&lt;&gt;(); pageSize = Optional.ofNullable(pageSize).orElse(500); List&lt;List&lt;T&gt;&gt; partition = Lists.partition(list, pageSize); for (List&lt;T&gt; tList : partition) { List&lt;R&gt; subList = function.apply(tList); if (!CollectionUtils.isEmpty(subList)) { result.addAll(subList); } } return result;} 对应设计模式为: 模板模式,","link":"/2021/03/17/%E4%BB%A3%E7%A0%81%E6%8A%80%E5%B7%A7-%E5%88%86%E6%89%B9%E6%9F%A5%E8%AF%A2/"},{"title":"代码技巧-redis分布式锁封装","text":"项目中频繁出现并发问题,并且无法代码解决时,我们会使用分布式锁进行把控 使用分布式锁后,在finally块中必须要进行释放,有没有发现需要写好多try-finally 优化背景举一个简单场景的例子 外送订单 –&gt; 创建配送单 –&gt;配送失败,被取消 –&gt;重新发起 所以一个订单统一时间只可以对应一个非取消的运单, 那么当上游同时使用相同的订单创建运单的时候,会出现同时校验通过,一个订单对应了两笔以上的非取消的单子,那么简单的方式就是使用一个分布式锁进行下控制 需要优化的代码123public void create(CreateDeliveryVo createDeliveryVo) { ... //省略代码} 分布式锁注意点假设A,B,C三个请求出现并发, 如果直接finally块中释放,可能会发生B线程将A线程的锁释放; 那么C线程会成功获取到锁 所以我们在释放时要加一步判断,是当前线程的锁再释放 优化前代码处理方式create重命名为createDelivery方法,使用分布式锁包装一层 12345678910111213141516@Override public void create(CreateDeliveryVo createDeliveryVo) { String lockKey = RedisLockConstants.DELIVERY_CREATE_LOCK_PREFIX + createDeliveryVo.getOrderId(); boolean lockSuccess = false; try { if (lockSuccess = redisLockManager.lock(lockKey, RedisLockConstants.DEFAULT_REDIS_WAIT_TIME_SECOND_10)) { createDelivery(createDeliveryVo); } } catch (Exception e) { log.error(&quot;create delivery error, e: {}&quot;, ThrowableUtil.getStackTrace(e)); } finally { if (lockSuccess) { redisLockManager.unLock(lockKey); } } } 思考事实上没啥问题,只不过我处理的项目里面这是一个简单的并发场景,实际上会存在很多互斥的请求,迫于无奈在多处增加了分布式锁,导致了代码可读性较差, 并且有些场景下获取锁失败需要额外的处理,因此考虑如何简化代码;提高可读性 优化封装需要使用锁的信息123456@Datapublic class RedisLockInfo{ private String key; private Integer expire; private TimeUnit timeUnit; } 定义锁异常1234public class LockException extends RuntimeException { //定义一下code或者其他信息, 主要是用于获取锁失败可能会进行额外处理} 统一封装加锁和释放锁的操作123456789101112131415161718192021@Componentpublic class RedisLockHelper{ @Autowired private RedisLockManager redisLockManager; //如果需要返回值; Runnable可以改为: Supplier&lt;T&gt; supplier public void execute(RedisLockInfo redisLockInfo, Runnable runnable) { boolean lockSuccess = false; try { if (lockSuccess = redisLockManager.lock(redisLockInfo.getKey(), redisLockInfo.getExipre(),redisLockInfo.getTimeUnit()) { runnable.run(); } } catch (Exception e) { throw new LockException(&quot;获取锁失败了&quot;); }finally { if (lockSuccess) { redisLockManager.unLock(redisLockInfo.getKey()); } } } } 调整后代码使用123456//RedisLockEntity 传key;其他会有默认值的构造器忽略不写了 public void create(CreateDeliveryVo createDeliveryVo) { redisLockHelper.execute(new RedisLockEntity(&quot;study.test.lock&quot;), () -&gt; { ... 原逻辑 }); }","link":"/2021/03/18/%E4%BB%A3%E7%A0%81%E6%8A%80%E5%B7%A7-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%B0%81%E8%A3%85/"},{"title":"volatile关键字","text":"volatile是Java虚拟机提供的最轻量级的同步机制,但是并不容易被完整的理解以至于许多程序员都习惯性的避免使用它 volatile特性当一个变量被定义为volatile后,它具备两项特性: 保证此变量对所有线程的可见性,这里的可见性是指当一个线程修改了这个变量的值,新值对其他线程来说是立即可知的 普通变量并不能保证这一点,普通变量 的值在线程之间需要通过主内存来完成,如:线程A修改一个普通变量的值,然后想主内存进行回写,另外一条线程B在线程A回写完成之后再对主内存进行读取操作,新变量值才会对线程B可见 volatile变量只是保证了可见性,但是无法保证原子性 适合使用volatile控制并发的有两种场景: 运算结果并不依赖变量的当前值,或者能够确保只有一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 个人梳理后的见解: 当一个volatile变量num发生运算时,num++操作 实际是有四条指令操作的结果,不具备原子性; 但是如果是一个num直接修改值则可以使用volatile进行并发控制,同理一个boolean的值变化就很适合用volatile控制 禁止指令重排序优化 普通变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取正确的结果,而不能保证变量赋值操作的顺序与程序代码中执行顺序一致 个人梳理后的见解: 使用volatile修饰的变量,在变量发生修改后,会通过指令lock add1 $0x0,(%esp)把本次的修改同步到内存中,意味着我们的代码在这里会是一个分界点,之前的操作已经全部走完了,因为这个volatile的变更前后不会被优化指令重排 总结 volatile变量在于主内存进行交互的时候, 变量读操作的性能消耗和普通变量的消息没有什么区别,但是写操作则会慢一些(因为需要在使用的代码中插入许多内存屏障指令来保证处理器不发生乱序执行) 大多数场景volatile的总开销要比锁来得低,是否使用volatile的唯一判断标准是volatile语义能否满足我们的场景使用","link":"/2021/05/05/volatile%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"配送优化整理","text":"在配送中做过哪些优化整理下在配送中对项目里的优化内容 日志优化 使用slf4j的MDC来无侵入的对所有日志增加链路追踪id;提升问题查询的效率 mq封装增加header;发送端和消费端之间日志关联 sql优化 排查索引,主流程的所有sql走执行计划 读写分离; 报表/及普通的B端功能走从库 数据归档 配送表字段多,表拆分 代码优化 主流程代码重构 使用redis分布式锁解决并发问题 使用rabbitmq来对大批量的外卖同步进行限流,同事使用redis的自减来对数据进行汇总 使用rabbitmq延时队列代替定时任务来精准控制运单创建时间 使用rabbitmq延时队列对运单状态变更做补偿任务 服务监控 接入skywalking 接入邮件告警 接入企业微信告警 增加配送预警功能; 对运单的下个状态进行预判 ; 做到提前告警","link":"/2020/12/06/%E5%9C%A8%E9%85%8D%E9%80%81%E4%B8%AD%E5%81%9A%E8%BF%87%E5%93%AA%E4%BA%9B%E4%BC%98%E5%8C%96/"},{"title":"AMQP基本概念","text":"AMQP定义 是面向消息的中间件的开放标准应用层协议,AMQP的特征是消息导向，排队，路由（包括点对点和发布和订阅），可靠性和安全性。 AMQP要求消息传递提供商和客户端的行为在不同供应商实现可互操作的情况下，以与SMTP，HTTP，FTP等相同的方式创建了可互操作的系统。 AMQP协议是具有现代特征的二进制协议。一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开发标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 AMQP是一种二进制应用层协议，旨在有效地支持各种消息应用和通信模式。 AMQP协议栈AMQP协议是一个二进制协议，拥有一些现代特点：多信道、协商式、异步、安全、跨平台、中立、高效。通常被划分为三层 Modle Layer (模型层)：位于协议最高层，主要定义了一些供客户端调用的命令，客户端可以利用这些命令实现自己的业务逻辑，例如，客户端可以通过queue.declare声明一个队列，利用consume命令获取一个队列中的消息。 Session Layer (会话层)：主要负责将客户端的命令发送给服务器，在将服务器端的应答返回给客户端，主要为客户端与服务器之间通信提供可靠性、同步机制和错误处理。 Transport Layer (传输层)：主要传输二进制数据流，提供帧的处理、信道复用、错误检测和数据表示。 AMQP核心概念 Server 又称为Broker,用于接收客户端的连接,实现AMQP实体服务 Connection 连接,应用程序与Broker的网络连接 Channel 网络信道,几乎所有的操作都在Channel中进行,Channel是进行消息读写的捅到,客户端可以建立多个Channel,每个Channel代表一个会话任务 Virtual Host 虚拟地址，是一个逻辑概念，用于进行逻辑隔离，是最上层的消息路由。一个Virtual Host里面可以有若干个Exchange和Queue，同一个Virtual Host里面不能有相同名称的Exchange或者Queue； Virtual Host是权限控制的最小粒度； Message 消息; 服务于与应用程序之间传输的数据; 由Properties和Body组成;Porperties可以对消息进行修饰,如延迟时间,优先级等特性;Body则是我们要传输的消息内容 仅仅创建了Connection是不能发送消息的,需要为每一个Connection创建Channel;AMQP协议规定只有Channel才能执行AMQP命令,一个Connection可以包含多个Channel; 因为TCP连接的建立和释放都是特别消耗资源的,如果每一个线程都直接与Broker进行交互,即:每个线程都建立一个TCP连接,那么操作系统无法职称特别高的TCP连接; RabbitMQ建议Channel不要共用; 至少保证每个Channel线程发送消息是串行的; 但是尽量共用Connection 信道本身的流量很大时，这时候多个信道复用一个 Connection 就会产生性能瓶颈，进而使整体的流量被限制了。此时就需要开辟多个 Connection，将这些信道均摊到这些 Connection 中，至于这些相关的调优策略需要根据业务自身的实际情况进行调节。 Exchange 交换机,用于接收消息,根据路由键将消息转发到绑定的队列 Binding Exchange和Queue之间的虚拟连接,Exchange在于多个Message Queue发送Binding后会生成一张路由表,存储这Message Queue所需要的限制条件; 这个条件就是RoutingKey; 当Exchange收到Message时会解析Header得到RoutingKey;Exchange根据RoutingKey与ExchangeType将Message路由到Message Queue中; BindingKey在Consumer声明Exchange和Message时指定;而RoutingKey由Producer发送Message时指定; 两者匹配方式都有Exchange Type决定 Routing Key 路由规则,虚拟机可用它来确定如何路由一个特定的消息 Queue 也称为Message Queue,即消息队列.用于保存消息并将他们转发给消费者 mq学习文章: @RabbitListener源码解析 中文文档","link":"/2021/05/17/AMQP%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"rabbitmq日志链路追踪","text":"mq增加全局链路追踪id 前言 在web请求中,通过通过实现HandlerInterceptor,将上游中传递的tid获取到放入本地线程变量中 在feign发送请求前,可以在构建feign的客户端时在SynchronousMethodHandler中增加全局RequestInterceptor 实现方式就是自定义一个RequestInterceptor的全局bean即可 当消息异步处理时(本文使用的中间介是rabbitMq),如何保证链路追踪id无侵入的传递 mq调研 rabbitmq的Message由Properties和Body组成,Properties类同与Http请求中的Header;统一对tid进行传递 MessagePostProcessor是消息的处理器;可以在发送消息前和接受消息后对消息进行处理,目前RabbitTemplate中存在两种PostProcessor,分别是:beforePublishPostProcessors和afterReceivePostProcessors debug跟踪消费端时发现接受消息和执行方法前有通过afterReceivePostProcessors对消息进行处理,但是方法执行后,只有部分逻辑可以对方法的返回值进行处理,并没有类似web拦截器HandlerInterceptor中执行后的逻辑处理 这里猜测spring-amqp在设计的时候, 支持在发送消息前修消息进行调整后再发送 , 消息都发送出去了不需要再做任何事情 支持在接受消息后对消息进行调整后再消息 , 没有考虑消息消费后再做后置处理(正常来说:需要吗?) 实现由于日志是通过SLF4J的MDC进行日志的打印,不可避免需要在方法执行后对本地线程变量执行释放操作,防止出现内存泄露问题,因此可以通过beforePublishPostProcessors在发送消息前进行处理,但是mq消费是需要通过aop来实现 mq生产者123456789101112@Componentpublic class RabbitTemplateConfig implements InitializingBean { @Autowired private RabbitTemplate rabbitTemplate; @Override public void afterPropertiesSet() throws Exception { rabbitTemplate.setBeforePublishPostProcessors(message -&gt; { message.getMessageProperties().setHeader(BusinessConstant.TID, &quot;abc&quot;); return message; }); }} mq消费者前提: 使用@RabbitListener注解来实现的 mq的高级特性支持在消费时入参可以是原生的Message,也可以直接用对象接受,目前公司项目并没有统一,因此需要做好兼容 Message作为方法入参时,Message存在Header信息,可以直接获取 对象作为方法入参是,需要额外增加Header; 可以通过@Header来获取 12345678910111213@RabbitListener(queues = MQConstant.TestQueue.TEST_QUEUE)public void execute(Message testMessage) { System.out.println(&quot;tid = &quot; + testMessage.getHeaders().get(TID)); System.out.println(&quot;testMessage.getPayload() = &quot; + testMessage.getPayload());} @RabbitListener(queues = MQConstant.TestQueue.TEST_QUEUE)public void execute1(@Payload TestMessage testMessage, @Header(name = TID,required = false) String tid) { System.out.println(&quot;tid = &quot; + tid); System.out.println(&quot;testMessage = &quot; + testMessage);} aop代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.caicai.rabbitmq.aop;import lombok.extern.slf4j.Slf4j;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.slf4j.MDC;import org.springframework.messaging.Message;import org.springframework.messaging.handler.annotation.Header;import org.springframework.stereotype.Component;import org.springframework.util.ObjectUtils;import java.lang.annotation.Annotation;import java.lang.reflect.Method;import java.util.Arrays;import static com.caicai.rabbitmq.constant.BusinessConstant.TID;@Slf4j@Aspect@Componentpublic class ConsumerLogAop { @Pointcut(value = &quot;execution(* com.caicai.rabbitmq.consumer.*.*(..))&quot;) private void pointcut() { } @Around(&quot;pointcut()&quot;) public Object doAroundAdvice(ProceedingJoinPoint joinPoint) throws Throwable { String headerTid = getHeaderTid(joinPoint); System.out.println(&quot;headerTid = &quot; + headerTid); Object resultObj = joinPoint.proceed(); return resultObj; } private static String getHeaderTid(ProceedingJoinPoint joinPoint) { try { MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); Annotation[][] annotations = method.getParameterAnnotations(); Object[] args = joinPoint.getArgs(); for (int i = 0; i &lt; args.length; i++) { Object arg = args[i]; if (arg instanceof Message) { Message message = (Message) arg; Object o = message.getHeaders().get(TID); return String.valueOf(o); } Annotation[] annotation = annotations[i]; for (Annotation anno : annotation) { if (anno.annotationType() == Header.class) { Header header = (Header) anno; if (ObjectUtils.nullSafeEquals(header.name(), TID)) { return String.valueOf(arg); } } } } } catch (Exception e) { } return null; }}","link":"/2021/05/17/rabbitmq%E6%97%A5%E5%BF%97%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"title":"spring-amqp基本概念","text":"[toc] AMQP定义 是面向消息的中间件的开放标准应用层协议,AMQP的特征是消息导向，排队，路由（包括点对点和发布和订阅），可靠性和安全性。 AMQP要求消息传递提供商和客户端的行为在不同供应商实现可互操作的情况下，以与SMTP，HTTP，FTP等相同的方式创建了可互操作的系统。 AMQP协议是具有现代特征的二进制协议。一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开发标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 AMQP是一种二进制应用层协议，旨在有效地支持各种消息应用和通信模式。 AMQP协议栈AMQP协议是一个二进制协议，拥有一些现代特点：多信道、协商式、异步、安全、跨平台、中立、高效。通常被划分为三层 Modle Layer (模型层)：位于协议最高层，主要定义了一些供客户端调用的命令，客户端可以利用这些命令实现自己的业务逻辑，例如，客户端可以通过queue.declare声明一个队列，利用consume命令获取一个队列中的消息。 Session Layer (会话层)：主要负责将客户端的命令发送给服务器，在将服务器端的应答返回给客户端，主要为客户端与服务器之间通信提供可靠性、同步机制和错误处理。 Transport Layer (传输层)：主要传输二进制数据流，提供帧的处理、信道复用、错误检测和数据表示。 AMQP核心概念 Server 又称为Broker,用于接收客户端的连接,实现AMQP实体服务 Connection 连接,应用程序与Broker的网络连接 Channel 网络信道,几乎所有的操作都在Channel中进行,Channel是进行消息读写的捅到,客户端可以建立多个Channel,每个Channel代表一个会话任务 Virtual Host 虚拟地址，是一个逻辑概念，用于进行逻辑隔离，是最上层的消息路由。一个Virtual Host里面可以有若干个Exchange和Queue，同一个Virtual Host里面不能有相同名称的Exchange或者Queue； Virtual Host是权限控制的最小粒度； Message 消息; 服务于与应用程序之间传输的数据; 由Properties和Body组成;Porperties可以对消息进行修饰,如延迟时间,优先级等特性;Body则是我们要传输的消息内容 仅仅创建了Connection是不能发送消息的,需要为每一个Connection创建Channel;AMQP协议规定只有Channel才能执行AMQP命令,一个Connection可以包含多个Channel; 因为TCP连接的建立和释放都是特别消耗资源的,如果每一个线程都直接与Broker进行交互,即:每个线程都建立一个TCP连接,那么操作系统无法职称特别高的TCP连接; RabbitMQ建议Channel不要共用; 至少保证每个Channel线程发送消息是串行的; 但是尽量共用Connection 信道本身的流量很大时，这时候多个信道复用一个 Connection 就会产生性能瓶颈，进而使整体的流量被限制了。此时就需要开辟多个 Connection，将这些信道均摊到这些 Connection 中，至于这些相关的调优策略需要根据业务自身的实际情况进行调节。 Exchange 交换机,用于接收消息,根据路由键将消息转发到绑定的队列 Binding Exchange和Queue之间的虚拟连接,Exchange在于多个Message Queue发送Binding后会生成一张路由表,存储这Message Queue所需要的限制条件; 这个条件就是RoutingKey; 当Exchange收到Message时会解析Header得到RoutingKey;Exchange根据RoutingKey与ExchangeType将Message路由到Message Queue中; BindingKey在Consumer声明Exchange和Message时指定;而RoutingKey由Producer发送Message时指定; 两者匹配方式都有Exchange Type决定 Routing Key 路由规则,虚拟机可用它来确定如何路由一个特定的消息 Queue 也称为Message Queue,即消息队列.用于保存消息并将他们转发给消费者 学习文章 @RabbitListener源码解析 中文文档","link":"/2021/05/16/spring-amqp/"}],"tags":[{"name":"quartz","slug":"quartz","link":"/tags/quartz/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"mq","slug":"mq","link":"/tags/mq/"},{"name":"aop","slug":"aop","link":"/tags/aop/"},{"name":"版本不兼容","slug":"版本不兼容","link":"/tags/%E7%89%88%E6%9C%AC%E4%B8%8D%E5%85%BC%E5%AE%B9/"},{"name":"双数据源","slug":"双数据源","link":"/tags/%E5%8F%8C%E6%95%B0%E6%8D%AE%E6%BA%90/"},{"name":"延时队列","slug":"延时队列","link":"/tags/%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/"},{"name":"Java关键字","slug":"Java关键字","link":"/tags/Java%E5%85%B3%E9%94%AE%E5%AD%97/"},{"name":"slf4j","slug":"slf4j","link":"/tags/slf4j/"},{"name":"日志","slug":"日志","link":"/tags/%E6%97%A5%E5%BF%97/"},{"name":"springretry","slug":"springretry","link":"/tags/springretry/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"Java内存模型","slug":"Java内存模型","link":"/tags/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}],"categories":[{"name":"定时任务","slug":"定时任务","link":"/categories/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"name":"mq","slug":"mq","link":"/categories/mq/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"中间介","slug":"中间介","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%8B/"},{"name":"Java虚拟机","slug":"Java虚拟机","link":"/categories/Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"开发工具","slug":"开发工具","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"springboot","slug":"springboot","link":"/categories/springboot/"},{"name":"办公工具","slug":"办公工具","link":"/categories/%E5%8A%9E%E5%85%AC%E5%B7%A5%E5%85%B7/"},{"name":"代码封装","slug":"代码封装","link":"/categories/%E4%BB%A3%E7%A0%81%E5%B0%81%E8%A3%85/"},{"name":"项目","slug":"项目","link":"/categories/%E9%A1%B9%E7%9B%AE/"}]}